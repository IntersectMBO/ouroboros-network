\chapter{System Architecture}
\hide{
\section{Overview}
This section describes the key underlying aspects and considerations of the design
of the network protocol and tries to give a big picture the overall network protocol.

\section{Key Functionality}

\wip{
  Here only an outline. Full discussion in the Section~\ref{ouroboros}.
\begin{description}
\item[Block diffusion]
\item[Chain following]
\item[Forwarding transactions]
\end{description}
}

\section{High Assurance Software}
\wip{How does the software/protocol design reflect the high assurance requirements ?}

\section{Modular Design and Mini Protocols}
\wip{Why are mini protocols a good idea ?}
\wip{How does polymorphism help modularity ?}
}

\section{Congestion Control}
A central design goal of the system is robust operation at high workloads.
For example, it is a normal working condition of the networking design
that transactions arrive at a higher rate than the number
that can be included in blockchain.
An increase of the rate at which transactions are submitted must not cause a decrease
of the block chain quality.

Point-to-point TCP bearers do not deal well with overloading.
A TCP connection has a certain maximal bandwidth,
i.e. a certain maximum load that it can handle relatively reliably under normal conditions.
If the connection is ever overloaded,
the performance characteristics will degrade rapidly unless
the load presented to the TCP connection is appropriately managed.

At the same time, the node itself has a limit on the rate at which it can process data.
In particular, a node may have to share its processing power with other processes that run on the
same machine/operation system instance, which means that a node may get slowed down for some reason,
and the system may get in a situation
where there is more data available from the network than the node can process.
The design must operate appropriately in this situation and recover form transient conditions.
In any condition, a node must not exceed its memory limits, 
that is there must be defined limits, breaches of which being treated like protocol violations.

Of cause it makes no sense if the system design is robust,
but so defensive that it fails to meet performance goals.
An example would be a protocol that never transmits a message unless it has received an
explicit ACK for the previous message. This approach might avoid overloading the network,
but would waste most of the potential bandwidth.

\hide{
\subsection{Back Pressure}
Back Pressure is a strategy for congestion control for push based buffered channels like
,for example, TCP connections.



\wip{TODO: explain the concept of Back pressure and how it is used in the design}
\subsection{Push vs Pull}
\wip{TODO: data flow inside the node is pull based}
\subsection{Delta Q}
\wip{TODO: explain what delta Q means and what it has to do with congestion control.}
}

\begin{figure}[ht]
  \pgfdeclareimage[height=10cm]{node-diagram-chains-state}{figure/node-diagram-concurrency.pdf}
  \begin{center}
    \pgfuseimage{node-diagram-chains-state}
  \end{center}
  \caption{Data flow inside a Node}
  \label{node-diagram-concurrency}
\end{figure}

\section{Data Flow in a Node}
Nodes maintain connections with the peers that have been chosen
with help of the peer selection process.
Suppose node $A$ is connected to node $B$.
The Ouroboros protocol schedules a node $N$ to generate a new block in a given time slot.
Depending on the location of nodes $A$, $B$ and $N$ in the network topology and whether the new
block arrives first at $A$ or $B$, $A$ can be either up-stream or down-stream of $B$.
Therefore, node $A$ runs an instance of the client side of the chain-sync mini protocol
that talks with a server instance of chain-sync at node $B$ and also a server instance of chain sync
that talks with a client instance at $B$.
The situation is similar for the other mini protocols (block fetch, transaction submission, etc).
The set of mini protocols that runs over a connection is determined by the version of the network
protocol, i.e.  Node-to-Node, Node-to-Wallet and Node-to-Chain-Consumer
connections use different sets of mini protocols (e.g. different protocol
versions).  The version is negotiated when a new connection is established
using protocol which is described in Chapter~\ref{connection-management}.
\hide{Add description of this protocol in Chapter~\ref{connection-management}
and link it.}

Figure~\ref{node-diagram-concurrency} illustrates parts of the data flow in a node.
Circles represents a thread that runs one of the mini protocols (the mini protocols are explained in
Chapter~\ref{state-machine-section}).
There are two kinds of data flows:
mini protocols communicate with mini protocols of other nodes by sending and receiving messages;
and, within a node, they communicate by reading from- and writing to- a shared
mutable state (represented by boxes in Figure~\ref{node-diagram-concurrency}).
\href{https://en.wikipedia.org/wiki/Software_transactional_memory}{Software transactional memory}
(STM) is a mechanism for safe and lock-free concurrent
access to mutable state and the reference implementation makes intensive use of this abstraction.

\section{Real-time Constraints and Coordinated Universal Time}
Ouroboros models the passage of physical time as an infinite sequence of time slots,
i.e. contiguous, equal-length intervals of time,
and assigns slot leaders (nodes that are eligible to create a new block) to those time slots.
At the beginning of a time slot, the slot leader selects the block chain and transactions that are the basis
for the new block, then it creates the new block and sends the new block to its peers.
When the new block reaches the next block leader before the beginning of next time slot,
the next block leader can extend the block chain upon this block (if the block
did not arrive on time the next leader will create a new block anyway).

There are some trade-offs when choosing the slot time that is used for the protocol but
basically the slot length should be long enough such that a new block has a good chance to reach the
next slot leader in time.
A chosen value for the slot length is 20 seconds.
It is assumed that the clock skews between the local clocks of the nodes is small with respect to the
slot length.

However, no matter how accurate the local clocks of the nodes are with respect to the time slots
the effects of a possible clock skew must still be carefully considered.
For example, when a node time-stamps incoming blocks with its local clock time, it may encounter
blocks that are created in the future
with respect to the local clock of the node.
The node must then decide whether this is because of a clock skew or whether the node considers this
as adversarial behaviour of an other node.

\wip{TODO :: get feedback from the researchers on this. Tentative policy: allow 200ms to 1s
explain the problem in detail.
A node cannot forward a block from the future.
This is complicated !
}

\chapter{Mini Protocols}
\label{state-machine-section}

\section{Mini Protocols and Protocol Families}
A mini protocol is a well defined and modular building block of
the network protocol.
Structuring the protocol around mini protocols helps to manage the overall complexity of
the design and adds useful flexibility.
The design turns into a family of protocols that can be specialised to particular requirements
by choosing a particular set of mini protocols.

The mini protocols in this section describe both the initiator and responder of a communication.
The initiator is the dual of the responder and vice versa.
(The terms client/server and consumer/producer are also used sometimes.)
At any time a node will typically run many instances of mini protocols, including many instances of the
same mini protocol.
Each mini protocol instance of the node communicates with the dual
instance of exactly one peer.
All mini protocols that communicate with the same peer
share a single communication channel (pipe or socket)
and a multiplexer/de-multiplexer is used to multiplex the protocols over that channel.
Section~\ref{multiplexing-section} describes the multiplexing layer.

The set of mini protocols that run on a connection between two participants of the system
depends on the role of the participants, i.e. whether the node acts as a full node or just
a block chain consumer, for example a wallet.
Section~\ref{peer-setup-section} describes how a connection between two nodes
that run a set of mini protocols is set up.

\section{Protocols as State Machines}
The reference implementation of several mini protocols uses a generic framework
for state machines.
\hide{
The Haskell implementation of the state machine framework is described in
Section~\ref{Haskell-state-machine}.
}
This framework uses correct-by-construction techniques to guarantee
several properties of the protocol and the implementation.
In particular, it guarantees that there are no deadlocks, i.e., at any time, one side has agency
(is expected to transmit the next message) and the other side is awaiting for
the message (or both sides agree that the protocol has terminated).
If either side receives a message that is not expected according to the protocol
the communication is aborted.

For each mini protocol that is based on this underlying framework the description provides the
following pieces of information:

\begin{itemize}
\item An informal description of the protocol.
\item States of the state machine.
\item The messages that are exchanged.
\item A transition graph of the global view of the state machine.
\item The client implementation of the protocol.
\item The server implementation of the protocol.
\end{itemize}

\begin{description}
\item[State Machine]
  Each mini protocol is described as a state machine.
  This document uses a simple diagram representations for state machines, and
  also includes corresponding transition tables.
  Descriptions of state machines in this section are directly derived from
  specifications of mini protocols using the state machine framework.

  The state machine framework that is used to specify the protocol can be instantiated
  with different implementations that work at different levels of abstraction
  (for example implementations used for simulation, implementations that run over virtual
  connections and implementations that actually transmit messages over the real network).
  

\item[States]
  States are abstract: they are not a value of some variables in a node, but
  rather describe the state of the two-party communication as whole, e.g.
  that a client is responsible for sending a particular type of message and
  the server is awaiting on it.  This, in particular, means that if the state
  machine is in a given state, both client and server are in this state.
  An additional piece of information that differentiates the roles of peers in
  a given state is agency, which describes which side is responsible for
  sending the next message.

  In the state machine framework, abstract states of a state machine are
  modelled as promoted types, so they do not correspond to any particular
  value hold by one of the peers.

  The document presents this abstract view of mini protocols and the state
  machines where the client and server are always in identical states, which
  also means that client and server simultaneously transit to new states.
  For this description network delays are not important.

  An interpretation, which is closer to the real-world implementation but
  less concise, is that there are independent client and server states
  and that transitions on either side happen independently when a message is sent or received.

\item[Messages]
  Messages exchanged by peers form edges of a state machine diagram, in other
  words they are transitions between states.
  They are elements from the set
  $$\{(label, data) \mid label \in Labels, data \in Data\}$$
  Protocols use a small set of $Labels$ typically $|Labels| \leq 10$.
  The state machine framework requires that messages can be serialised,
  transferred over the network and de-serialised by the receiver.
  The binary format for messages is described in Section~\ref{CBOR-section}.

\item[Agency]
  A node has agency if it is expected to send the next message.
  In every state (except the \Done-state) either the client or server has agency.
  In the \Done-state the protocol has terminated and neither side is expected to send any more
  messages.

\item [State machine diagrams]
      States are drawn as circles in state machine diagrams.
      States with agency at the client are drawn in green, states with agency at the server in blue and
      the \Done-state in black.
      By construction, the system is always in exactly one state,
      i.e. the client's state is always the same state as server's,
      and the colour indicates who is the agent.
      It is also important to understand that the arrows in the state transition diagram denote
      state transitions and not the direction of the message that is being transmitted.
      For the agent of the particular state it will mean send a message to the
      other peer, for a non-agent, listen for incoming message.
      This may be confusing because the arrows are labeled with the messages and
      many arrows go from a green state (client has the agency) to a blue
      state (server has the agency) or vice versa.

%TODO: find a latex style to mark tricky sections that must be read carefully.

\begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=4.5cm, semithick]
  \tikzstyle{every state}=[fill=red,draw=none,text=white]
  \node[state, green]              (A)      {$A$};
  \node[state, blue ,right of=A]   (B)      {$B$};
  \draw (A)            edge[above]          node{Message}   (B);
\end{tikzpicture}

      $A$ is green, i.e in state $A$ the client has agency.
      Therefore the client sends a message to the server and
      both client and server transition to state $B$.
      As $B$ is blue the agency also changes from client so server.

\begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=4.5cm, semithick]
  \tikzstyle{every state}=[fill=red,draw=none,text=white]
  \node[state, blue]               (C)      {$C$};
  \node[state, blue ,right of=A]   (D)      {$D$};
  \draw (A)            edge[above]               node{Message}   (B);
\end{tikzpicture}

      $C$ is blue, i.e in state $C$ the server has agency.
      Therefore the server sends a message to the client and
      both client and server transition to state $D$.
      As $D$ is also blue the agency remains at the server.

\item[Client and server implementation]
  The state machine describes which messages are sent and received and in which order.
  This is the external view of the protocol that every compatible implementation MUST follow.
  In addition to the external view of the protocol, this part of the specification describes
  how the client and server actually process the transmitted messages,
  i.e. how the client and server update their internal mutable state
  upon the exchange of messages.

  Strictly speaking, the representation of the node-local mutable state
  and the updates to the node-local state are implementation details that are
  not part of the communication protocol between the nodes,  and will
  depend on an application that is built on top of the network service
  (wallet, core node, explorer, etc.).
  The corresponding sections were added to clarify mode of operation of the
  mini protocols.

\end{description}
\section{Overview of all implemented Mini Protocols}

\newcommand{\miniEntry}[4]{
    \hline
    #1 & Section \ref{#2} \\
    \multicolumn{2}{|l|} {#3} \\
    \multicolumn{2}{|l|} {\hsref{#4}}\\ \hline
    \multicolumn{2}{l} {} \\
}

\begin{tabular}{|lr|}
  \miniEntry
      {Ping Pong Protocol}
      {ping-pong-protocol}
      {A simple ping-pong protocol for testing.}
      {typed-protocols/src/Network/TypedProtocol/PingPong/Type.hs}

  \miniEntry
      {Request Response Protocol}
      {request-response-protocol}
      {A protocol similar to ping pong but which exchanges data.}
      {} % no Haskell source ?

  \miniEntry
      {Chain Synchronisation Protocol}
      {chain-sync-protocol}
      {}
      {ouroboros-network/src/Ouroboros/Network/Protocol/ChainSync/Type.hs}

  \miniEntry
      {Block Fetch Protocol}
      {block-fetching-protocol}
      {The block fetching mechanism enables a node to download a range of blocks.}
      {ouroboros-network/src/Ouroboros/Network/Protocol/BlockFetch/Type.hs}

  \miniEntry
      {Local Transaction Submission Mini Protocol}
      {local-tx-submission-protocol}
      {Transmitting Transactions for a wallet to a core node}
      {src/Ouroboros/Network/Protocol/LocalTxSubmission/Type.hs}

  \miniEntry
      {Handshake Mini Protocol}
      {handshake-protocol}
      {This protocol is used for version negotiation.}
      {src/Ouroboros/Network/Protocol/Handshake/Type.hs}
\end{tabular}

\section{Ping-Pong Protocol}
\label{ping-pong-protocol}
\hsref{typed-protocols/src/Network/TypedProtocol/PingPong/Type.hs}
\newcommand{\Ping}{\msg{Ping}}
\newcommand{\Pong}{\msg{Pong}}

\subsection{Description}
A client can use the Ping-Pong protocol to check that the server is responsive.
The Ping-Pong protocol is very simple because the messages do not carry any data and
because the Ping-Pong client and the Ping-Pong server do not access the internal state of the node.
It uses the same framework for state machines as the other protocols,
but because the protocol is so simple,
the description of the protocol is also very simple and slightly
different from descriptions of other protocols.

\subsection{State Machine}

\begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=4.5cm, semithick]
  \tikzstyle{every state}=[fill=red,draw=none,text=white]
  \node[state, green, initial]                            (Idle)      {\Idle};
  \node[state, right of=Idle]                             (Done)      {\Done};
  \node[state, blue, below of=Idle]                       (Busy)      {\Busy};

  \draw (Idle)         edge[above]               node{\MsgDone}                  (Done);
  \draw (Idle)         edge[left, bend right]    node{\Ping}                     (Busy);
  \draw (Busy)         edge[right, bend right]   node{\Pong}                     (Idle);
\end{tikzpicture}

\begin{figure}[ht]
\begin{tabular}{|l|l|} \hline
\multicolumn{2}{|c|}{Agency} \\ \hline
  Client has Agency & \Idle \\  \hline
  Server has Agency & \Busy \\  \hline
\end{tabular}
\end{figure}

The protocol uses the following messages.
The messages of the Ping-Pong protocol do not carry any data.
\begin{description}
\item [\Ping]
      The client sends a Ping request to the server.
\item [\Pong]
      The server replies to a Ping with a Pong.
\item [\MsgDone]
      Terminate the protocol.
\end{description}

\begin{tabular}{|l|l|l|}
  \hline
  \multicolumn{3}{|c|}{Transition table} \\ \hline
  from state   & message            & to state    \\ \hline\hline
  \Idle        & \Ping              & \Busy   \\ \hline
  \Busy        & \Pong              & \Idle   \\ \hline
  \Idle        & \MsgDone           & \Done       \\ \hline
\end{tabular}

\section{Request Response Protocol}
\label{request-response-protocol}
\renewcommand{\Idle}{\state{Idle}}
\renewcommand{\Busy}{\state{Busy}}
\renewcommand{\Done}{\state{Done}}
\newcommand{\Request}{\msg{Request}}
\newcommand{\Response}{\msg{Response}}

\subsection{Description}
The request response protocol is polymorphic in the request and response data that is being transmitted.
This means that there are different possible applications of this protocol and the
application of the protocol determines the types of the requests and responses.

\subsection{State machine}
\hsref{ouroboros-network/src/Ouroboros/Network/Protocol/ReqResp/Type.hs}

\begin{tabular}{|l|l|}
  \hline
  \multicolumn{2}{|c|}{Agency} \\ \hline
  Client has Agency & \Idle \\  \hline
  Server has Agency & \Busy \\ \hline
\end{tabular}
{\vskip 10pt}
\begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=4.5cm, semithick]
  \tikzstyle{every state}=[fill=red,draw=none,text=white]
  \node[state, green, initial]                                   (Idle)      {\Idle};
  \node[state, blue, right of=Idle]                              (Busy)      {\Busy};
  \node[state, right of=Busy]                                    (Done)      {\Done};

  \draw (Idle)         edge[]      node{\Request}           (Busy);
  \draw (Busy)         edge[]      node{\Response}          (Done);
\end{tikzpicture}
{\vskip 10pt}
\begin{tabular}{|l|l|l|l|} \hline
\multicolumn{4}{|c|}{Transition table} \\ \hline
  from         & message            & parameters             & to       \\ \hline\hline
  \Idle        & \Request           & $request$              & \Busy     \\ \hline
  \Busy        & \Response          & $response$             & \Done     \\ \hline
\end{tabular}

\section{Chain Synchronisation Protocol}
\label{chain-sync-protocol}
\hsref{ouroboros-network/src/Ouroboros/Network/Protocol/ChainSync/Type.hs}
\newcommand{\CanAwait}{\state{CanAwait}}
\newcommand{\MustReply}{\state{MustReply}}
\newcommand{\Intersect}{\state{Intersect}}
\newcommand{\RequestNext}{\msg{RequestNext}}
\newcommand{\AwaitReply}{\msg{AwaitReply}}
\newcommand{\RollForward}{\msg{RollForward}}
\newcommand{\RollBackward}{\msg{RollBackward}}
\newcommand{\FindIntersect}{\msg{FindIntersect}}
\newcommand{\IntersectFound}{\msg{IntersectFound}}
\newcommand{\IntersectNotFound}{\msg{IntersectNotFound}}

\subsection{Description}
The chain synchronisation protocol is used by the block chain consumer
to replicate the producer's block chain locally. As it is polymorphic in blocks,
it supports a family of Ouroboros protocols.
The chain synchronisation protocol is used by clients that synchronise just headers (node-to-node),
and also clients which synchronize actual block chains (e.g., node-to-wallet).
(See Figure~\ref{node-diagram-concurrency}.)

A node communicates with several upstream and downstream nodes.
A node runs an independent client instance and a independent server instance for every
other node it communicates with.

\subsection{State Machine}

\begin{tabular}{|l|l|}
  \hline
  \multicolumn{2}{|c|}{Agency} \\ \hline
  Client has Agency & \Idle \\  \hline
  Server has Agency & \CanAwait, \MustReply, \Intersect \\ \hline
\end{tabular}

\begin{figure}[ht]
\begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=4.5cm, semithick]
  \tikzstyle{every state}=[fill=red,draw=none,text=white]
  \node[state, green, initial]                            (Idle)      {\Idle};
  \node[state, right of=Idle]                             (Done)      {\Done};
  \node[state, blue, below left of=Idle]                  (CanAwait)  {\CanAwait};
  \node[state, blue, right of=CanAwait]                   (MustReply) {\MustReply};
  \node[state, blue, above of=Idle]                       (Intersect) {\Intersect};

  \draw (Idle)         edge[left, bend right]      node{\RequestNext}           (CanAwait);
  \draw (CanAwait)     edge[below, bend right]     node{\AwaitReply}            (MustReply);
  \draw (CanAwait)     edge[above,bend right=45]     node{\RollForward}           (Idle);
  \draw (MustReply)    edge[right,bend right=45]     node{\RollForward}           (Idle);
  \draw (CanAwait)     edge[above,bend right=80]     node{\RollBackward}          (Idle);
  \draw (MustReply)    edge[right,bend right=80]     node{\RollBackward}          (Idle);
  \draw (Idle)         edge[right, bend right]    node{\FindIntersect}         (Intersect);
  \draw (Intersect)    edge[above, bend right=45]    node[below = 4mm]{\IntersectFound}     (Idle);
  \draw (Intersect)    edge[above, bend right=80]    node[above = 4mm]{\IntersectNotFound}  (Idle);
  \draw (Idle)         edge[above]                node{\MsgDone}                  (Done);
\end{tikzpicture}
\caption{State machine of the chain sync protocol.}
\label{chain-sync-automata}
\end{figure}

The protocol uses the following messages:
\begin{description}
\item [\RequestNext]
      Request the next update from the producer.
\item [\AwaitReply]
      Acknowledge the request but require the consumer to wait for the next update.
      This means that the consumer is synced with the producer, and
      the producer is waiting for its own chain state to change.
\item [\RollForward{} {\boldmath $(header,point)$}]
      Tell the consumer to extend their chain with the given $header$.
      The message also tells the consumer about the $head$ point of the producer.
\item [\RollBackward{} {\boldmath $(point_{old},point_{head})$}]
      Tell the consumer to roll back to a given $point_{old}$ on their chain.
      The message also tells the consumer about the current head $point_{head}$ of the producer.
\item [\FindIntersect{} {\boldmath $\langle point_{head} \rangle $}]
      Ask the producer to try to find an improved intersection point between
      the consumer and producer's chains.
      The consumer sends a sequence {\boldmath $\langle point \rangle $}
      and it is up to the producer
      to find the first intersection point on its chain and send it back to the consumer.
\item [\IntersectFound{} {\boldmath $(point_{intersect},point_{head})$}]
      The producer replies with the first point of the request that is on his current chain.
      The consumer can decide whether to send more points.
      The message also tells the consumer about the head point of the producer.
\item [\IntersectNotFound{} {\boldmath $(point_{head})$}]
      The reply to the consumer that no intersection was found: none of the
      points the consumer supplied are on the producer chain.
      The message also tells the consumer about the head point of the producer.
\item [\MsgDone]
      Terminate the protocol.
\end{description}

\begin{tabular}{|l|l|l|l|}
  \hline
  \multicolumn{4}{|c|}{Transition table} \\ \hline
  from state & message             & parameters                          & to state    \\ \hline\hline
  \Idle      & \RequestNext        &                                     & \CanAwait   \\ \hline
  \Idle      & \FindIntersect      & $\langle point\rangle$              & \Intersect  \\ \hline
  \Idle      & \MsgDone            &                                     & \Done       \\ \hline
  \CanAwait  & \AwaitReply         &                                     & \MustReply  \\ \hline
  \CanAwait  & \RollForward        & $header$, $point_{head}$            & \Idle       \\ \hline
  \CanAwait  & \RollBackward       & $header$, $point_{head}$            & \Idle       \\ \hline
  \MustReply & \RollForward        & $header$, $point_{head}$            & \Idle       \\ \hline
  \MustReply & \RollBackward       & $point_{old}$, $point_{head}$       & \Idle       \\ \hline
  \Intersect & \IntersectFound     & $point_{intersect}$, $point_{head}$ & \Idle       \\ \hline
  \Intersect & \IntersectNotFound  & $point_{head}$                      & \Idle       \\ \hline

\end{tabular}

\newcommand{\readpointer}{\emph{read-pointer}}
\subsection{Implementation of the Chain Producer}
\hide{The trade-offs between the robustness and efficiency of possible chain-sync protocols are
discussed in Section~\ref{chain-sync-discussion}.
}
This section describes a state-full implementation of a chain producer that is suitable for a setting where
the producer cannot trust the chain consumer.
An important requirement in this setting
is that a chain consumer must never be able to cause excessive resource use on the producer side.
The presented implementation meets this requirement.
It uses a constant amount of memory to store the state that the producer maintains
per chain consumer.  This protocol is only used to reproduce the producer
chain locally by consumer.  By running many instances of this protocol against
different peers, a node can reproduce chains in the network and
do chain selection which by design is not part of this protocol.
Note, that when we refer to the consumer's chain in this section, we mean the
the chain that is reproduced by the consumer with the instance of
the chain-sync protocol under consideration and not the result of the chain selection algorithm.

We call the state which the producer maintains about the consumer the \readpointer{}.
The \readpointer{} basically tracks what the producer knows about the head of
the consumer's chain without storing it locally.
It points to a block on the current chain of the chain producer.
The \readpointer{}s are part of the shared state of the node (Figure~\ref{node-diagram-concurrency}) and
\readpointer{}s are concurrently updated by the thread that runs the chain-sync mini-protocol and the
chain tracking logic of the node itself.

We first describe how the mini-protocol updates a \readpointer{} and later address what happens in case
of a fork.
\subparagraph{Initializing the \readpointer{}.}
The chain producer assumes that a consumer, which has just connected,
only knows the genesis block and initializes the \readpointer{} of that consumer
with a pointer to the genesis block on its chain.

\subparagraph{Downloading a chain of blocks}
A typical situation is when the consumer follows the chain of the producer but is not yet at the head of the
chain (this also covers a consumer booting from genesis).
In this case, the protocol follows a simple, consumer-driven, request-response pattern.
The consumer sends \RequestNext{} messages to ask for the next block.
If the \readpointer{} is not yet at the head of the chain,
the producer replies with a \RollForward{} and advances the \readpointer{} to
the next block (optimistically assuming that the client will update its chain
accordingly).
The \RollForward{} message contains the next block and also the head-point of the producer.
The protocol follows this pattern until the \readpointer{} reaches the end of its chain.

\begin{figure}[ht]
\pgfdeclareimage[height=7cm]{read-pointer-consumer-driver}{figure/read-pointer-consumer-driven.pdf}
\begin{center}
\pgfuseimage{read-pointer-consumer-driver}
\end{center}
\caption{Consumer driven block download.}
\label{read-pointer-consumer-driver}
\end{figure}

\subparagraph{Producer driven updates}
If the \readpointer{} points to the end of the chain and the producer receives
a \RequestNext{}
the consumers chain is already up to date.
The producer informs the consumer with an \AwaitReply{} that no new data is available.
After receiving a \AwaitReply, the consumer just waits for a new message and the producer keeps agency.
The \AwaitReply{} switches from a consumer driven phase to a producer driven phase.

The producer waits until new data becomes available.
When a new block is available, the producer will
send a \RollForward{} message and give agency back to the consumer.
The producer can also get unblocked when its node switches to a new chain fork.

\subparagraph{Producer switches to a new fork}
The node of the chain producer can switch to a new fork at any time, independent of the
state machine.
A chain switch can cause an update of the \readpointer{},
which is part of the mutable state that is shared between the thread that runs
the chain sync protocol and the thread that implements the chain following logic of the node.
There are two cases:

1) If the \readpointer{} points to a block that is on the common prefix of the new
fork and the old fork, no update of the \readpointer{} is needed.

2) If the \readpointer{} points to a block that is no longer part of the chain that is followed by the node,
the \readpointer{} is set to the last block that is common between the new and the old chain.
The node also sets a flag that signals the chain-sync thread to send a \RollBackward{} instead
of a \RollForward.
Finally the producer thread must unblock if it is in the \MustReply{} state.

\begin{figure}[ht]
\pgfdeclareimage[height=5cm]{read-pointer-rollback}{figure/read-pointer-rollback.pdf}
\begin{center}
\pgfuseimage{read-pointer-rollback}
\end{center}
\caption{\readpointer{} update for a fork switch in case of a rollback.}
\label{read-pointer-rollback}
\end{figure}

Figure~\ref{read-pointer-rollback} illustrates a fork switch that requires an update of the \readpointer{}
for one of the chain consumers, i.e. an example for case 2.
Before the switch, the \readpointer{} of the consumer points to block $0x660f$.
The producer switches to a new chain with the head of the chain at block $0xcdf0$.
The node must update the \readpointer{} to block $0xfa40$ and the next message to the consumer
will be a \RollBackward.

Note, that a node typically communicates with several consumers. For each consumer it runs an independent
version of the chain-sync-protocol state machine in an independent thread and with its own \readpointer{}.
Each of those \readpointer{}s has to be updated independently and for each consumer
either case 1) or case 2) can apply.

\subparagraph{Consumer starts with an arbitrary fork}
Typically, the consumer already knows some fork of the block chain when it
starts to track the producer.
The protocol provides an efficient method to search for the longest common prefix (here called intersection)
between the fork of the producer and the fork that is known to the consumer.

To do so, the consumer sends a \FindIntersect{} message with a list of chain
points which belong to its node chain.
If the producer does not know any of the points it replies with \IntersectNotFound.
Otherwise it replies with \IntersectFound{} and the best (i.e. the newest) of the points that it knows
and also updates the \readpointer{} accordingly.
For efficiency, the consumer should use a binary search scheme to search for the longest common
prefix.

It is advised that the consumer always starts with \FindIntersect{} in a fresh connection
and it is free to use \FindIntersect{} at any time later as seems beneficial.
If the consumer does not know anything about the producer's chain,
it can start the search with the following list of points:
$\langle point(b), point(b-1), point(b-2), point(b-4), point (p-8),\ldots \rangle$
where $point(b-i)$ is the point of the $i$th predecessor of block $b$ and
$b$ is the head of the consumer fork.
\wip{(Note, that the maximum depth of a fork in Ouroboros is bounded).}

\subsection{Implementation of the Chain Consumer}
In principle, the chain consumer has to guard against a malicious chain producer
as much as the other way around.
However, two aspects of the protocol play in favour of the consumer here.
\begin{itemize}
  \item The protocol is basically consumer driven, i.e. the producer has no way to send unsolicited
data to the consumer (within the protocol).
  \item The consumer can verify the response data itself.
\end{itemize}
Here are some cases to consider:
\begin{description}
\item[\FindIntersect~Phase]
  The consumer and the producer play a number guessing game, so the consumer can easily detect
  inconsistent behaviour.
\item[The producer replies with a \RollForward] The consumer can verify the block itself
  with the help of the ledger layer.
  (The consumer may need to download the block first, if the protocol only sends block headers.)
\item[The producer replies with a \RollBackward] The consumer tracks several producers, so
  if the producer sends false \RollBackward{} messages the consumer's node
  will, at some point, just switch to a longer chain fork.
\item[The Producer is just passive/slow] The consumer's node will switch to
  a longer chain coming from another producer via another instance of
    chain-sync protocol.
\end{description}
\wip{This should be explained in detail}

\section{Block Fetch Protocol}
\label{block-fetching-protocol}

\hsref{ouroboros-network/src/Ouroboros/Network/Protocol/BlockFetch/Type.hs}
\renewcommand{\Idle}{\state{Idle}}
\renewcommand{\Busy}{\state{Busy}}
\newcommand{\Streaming}{\state{Streaming}}
\renewcommand{\Done}{\state{Done}}
\newcommand{\RequestRange}{\msg{RequestRange}}
\newcommand{\StartBatch}{\msg{StartBatch}}
\newcommand{\NoBlocks}{\msg{NoBlocks}}
\newcommand{\Block}{\msg{Block}}
\newcommand{\BatchDone}{\msg{BatchDone}}
\newcommand{\ClientDone}{\msg{ClientDone}}

\subsection{Description}

The block fetching mechanism enables a node to download a range of blocks.

\subsection{State machine}

\begin{tabular}{|l|l|}
  \hline
  \multicolumn{2}{|c|}{Agency} \\ \hline
  Client has Agency & \Idle            \\  \hline
  Server has Agency & \Busy, \Streaming \\ \hline
\end{tabular}

\begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=4.5cm, semithick]
  \tikzstyle{every state}=[fill=red,draw=none,text=white]
  \node[state, green, initial]                            (Idle)      {\Idle};
  \node[state, right of=Idle]                             (Done)      {\Done};
  \node[state, blue, below left of=Idle]                  (Busy)      {\Busy};
  \node[state, blue, right of=CanAwait]                   (Streaming) {\Streaming};

  \draw (Idle)         edge[above]                node{\ClientDone}                  (Done);
  \draw (Idle)         edge[left,bend right]      node{\RequestRange}                (Busy);
  \draw (Busy)         edge[above,bend right]     node{\NoBlocks}                    (Idle);
  \draw (Busy)         edge[below]                node{\StartBatch}                  (Streaming);
  \draw (Streaming)    edge[loop right]           node{\Block}                       (Streaming);
  \draw (Streaming)    edge[right]                node{\BatchDone}                   (Idle);
\end{tikzpicture}

\begin{description}
\item [\RequestRange{} {\boldmath $(range)$}]
  The client requests a {\boldmath $range$} of blocks from the server.
\item [\NoBlocks]
  The server tells the client that it does not have blocks.
\item [\StartBatch]
  The server starts block streaming.
\item [\Block{} {\boldmath $(body)$}]
  Stream a single block's body.
\item [\BatchDone]
  The server ends block streaming.
\item [\ClientDone]
  The client terminates the protocol.
\end{description}

Transition table:

\begin{tabular}{|l|l|l|l|}
  \hline
  \multicolumn{4}{|c|}{Transition table} \\ \hline
  from state   & message             & parameters             & to state    \\ \hline\hline
  \Idle        & \ClientDone         &                        & \Done       \\ \hline
  \Idle        & \RequestRange       & $range$                & \Busy       \\ \hline
  \Busy        & \NoBlocks           &                        & \Idle       \\ \hline
  \Busy        & \StartBatch         &                        & \Streaming  \\ \hline
  \Streaming   & \Block              & $body$                 & \Streaming  \\ \hline
  \Streaming   & \BatchDone          &                        & \Idle       \\ \hline
\end{tabular}

\section{Local Transaction Submission Mini Protocol}
\hsref{src/Ouroboros/Network/Protocol/LocalTxSubmission/Type.hs}
\label{local-tx-submission-protocol}
\subsection{Description}
The local transaction submission mini protocol is used by local clients,
for example wallets or CLI tools, to submit transactions to a local node.
The protocol is {\bf not} used to forward transactions from one core node to an other.

The protocol follows a simple request-response pattern:
\begin{enumerate}
\item The client sends a request with a single transaction.
\item The Server either accepts the transaction (returning a confirmation) or rejects it (returning the
  reason).
\end{enumerate}
Note, that the local transaction submission protocol is a push bases protocol where the client
creates a workload for the server.
This is acceptable because is protocol is only for use between a node and local client.
\newcommand{\SubmitTx}{\trans{SubmitTx}}
\newcommand{\AcceptTx}{\trans{AcceptTx}}
\newcommand{\RejectTx}{\trans{RejectTx}}
\subsection{State machine}

\begin{tabular}{|l|l|}
  \hline
  \multicolumn{2}{|c|}{Agency} \\ \hline
  Client has Agency & \Idle \\ \hline
  Server has Agency & \Busy \\  \hline
\end{tabular}

\begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=4cm, semithick]
  \tikzstyle{every state}=[fill=red,draw=none,text=white]
  \node[state, blue, initial]                                     (Idle)       {\Idle};
  \node[state, right of=Idle]                                     (Done)       {\Done};
  \node[state, green, above of=Idle]                              (Busy)     {\Busy};

  \draw (Idle)         edge[]                          node{\MsgDone}           (Done);
  \draw (Idle)         edge[right, bend right=45]      node{\SubmitTx}          (Busy);
  \draw (Busy)         edge[left, bend right=45]       node[below = 3mm]{\AcceptTx}          (Idle);
  \draw (Busy)         edge[left, bend right=80]       node[above = 3mm]{\RejectTx}          (Idle);
\end{tikzpicture}

Messages of the protocol:
\begin{description}
\item [\SubmitTx{} {\boldmath $(t)$}]
      The client submits a transaction.
\item [\AcceptTx]
      The server accepts the transaction.
\item [\RejectTx{} {\boldmath $(reason)$}]
      The server rejects the transactions and replies with the $reason$.
\item [\MsgDone]
      The client terminates the mini protocol.
\end{description}

\section{Handshake Mini Protocol}
\hsref{src/Ouroboros/Network/Protocol/Handshake/Type.hs}
\label{handshake-protocol}
\newcommand{\Propose}{\state{Propose}}
\newcommand{\Confirm}{\state{Confirm}}
\newcommand{\ProposeVersions}{\msg{ProposeVersions}}
\newcommand{\AcceptVersion}{\msg{AcceptVersion}}
\newcommand{\Refuse}{\msg{Refuse}}

\newcommand{\VersionMismatch}{\msg{VersionMismatch}}
\newcommand{\HandshakeDecodeError}{\msg{HandshakeDecodeError}}
\newcommand{\Refused}{\msg{Refused}}

\subsection{Description}
The handshake mini protocol is used to negotiate the protocol version
and the protocol parameters that are used by the client and the server.
It is run exactly once when a new connection is initialized
and consists of a single request from the client and a single reply from the server.
Section \ref{peer-setup-section} explains the live cycle of a connection and the role of
the handshake mini protocol in more detail.

The handshake mini protocol is a generic protocol that can negotiate any kind protocol parameters.
It only assumes that protocol parameters can be encoded to, and decoded from, CBOR terms.
A node, that runs the handshake protocol, must instantiate it with the set of
supported protocol versions and callback functions for handling the protocol parameters.
These callback functions are specific for the supported protocol versions.

\subsection{State machine}

\begin{tabular}{|l|l|}
  \hline
  \multicolumn{2}{|c|}{Agency} \\ \hline
  Client has Agency & \Propose \\ \hline
  Server has Agency & \Confirm \\  \hline
\end{tabular}

\begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=5cm, semithick]
  \tikzstyle{every state}=[fill=red,draw=none,text=white]
  \node[state, green, initial]                                     (Propose)    {\Propose};
  \node[state, blue, right of=Propose]                             (Confirm)    {\Confirm};
  \node[state, right of=Confirm]                                   (Done)       {\Done};

  \draw (Propose)      edge[]      node{\ProposeVersions}          (Confirm);
  \draw (Confirm)      edge[above, bend left]       node{\AcceptVersion}     (Done);
  \draw (Confirm)      edge[below, bend right]      node{\Refuse}            (Done);

\end{tikzpicture}

Messages of the protocol:
\begin{description}
\item [\ProposeVersions{} {\boldmath $(versionTable)$}]
      The client proposes a number of possible versions and protocol parameters.
\item [\AcceptVersion{} {\boldmath $(versionNumber,extraParameters)$}]
      The server accepts $versionNumber$ and returns possible extra protocol parameters.
\item [\Refuse{} {\boldmath $(reason)$}]
      The server refuses the proposed versions.
\end{description}

\begin{tabular}{|l|l|l|l|} \hline
\multicolumn{4}{|c|}{Transition table} \\ \hline
  from        & message/event      & parameters                   & to          \\ \hline\hline
  \Propose    & \ProposeVersions   & $versionTable$              & \Confirm    \\ \hline
  \Confirm    & \AcceptVersion     & $(versionNumber,extraParameters)$ & \Done \\ \hline
  \Confirm    & \Refuse            & $reason$                     & \Done \\ \hline
\end{tabular}

\subsection{Client and Server Implementation}
Section~\ref{included-cddl} contains the CDDL-specification of the binary format of the handshake messages.
The version table is encoded as a CBOR table with the version number as key
and the protocol parameters as value.
The handshake protocol requires that the version numbers ( i.e. the keys) in the version table are unique
and appear in ascending order.
(Note, that CDDL is not expressive enough to precisely specify that requirement on the keys of the CBOR
table. Therefor the CDDL-specification uses a table with keys from 1 to 4 as an example.)

In a run of the handshake mini protocol the peers exchange only two messages:
The client requests to connect with a \ProposeVersions{} message that contains information about
all protocol versions it wants to support.
The server replies either with an \AcceptVersion{} message containing the negotiated
version number and extra parameters or a \Refuse{} message.
The \Refuse{} message contains one of three alternative refuse reasons:
\VersionMismatch{}, \HandshakeDecodeError{} or just \Refused{}.

When a server receives a \ProposeVersions{} message it uses the following algorithm to
compute the response:
\begin{enumerate}
\item
  Compute the intersection of the set of protocol version numbers that the server support
  and the version numbers requested by the client.
\item
  If the intersection is empty:
  Reply with \Refuse(\VersionMismatch) and the list of protocol numbers the server supports.
\item
  Otherwise:
  Select the protocol with the highest version number in the intersection.
\item
  Run the protocol specific decoder on the CBOR term that contains the protocol parameters.
\item
  If the decoder fails:
  Reply with \Refuse(\HandshakeDecodeError), the selected version number and an error message.
\item
  Otherwise: Test the proposed protocol parameters of the selected protocol version
\item
  If the test refuses the parameters:
  Reply with \Refuse(\Refused), the selected version number and an error message.
\item
  Otherwise:
  Encode the extra parameters and
  reply with \AcceptVersion, the selected version number and the extra parameters.
\end{enumerate}
Note, that in step 4), 6) and 8) the handshake protocol uses the callback functions that are specific
for set of protocols that the server supports.
The handshake protocol is designed,
such that a server can allways handle requests for protocol versions that it does not support.
The server simply ignores the CBOR terms that represent the protocol parameters of unsupported
version.

\wip{
see in the code if this is still true:
The handshake mini protocol runs before the MUX/DEMUX itself is initialized.
Each message is transmitted within a single MUX segment, i.e. with a proper segment header,
but, as the MUX/DEMUX is not yet running the messages must not be split into multiple segments.
}

\section{Pipelining of Mini Protocols}
\label{pipelining}
Protocol pipelining is a technique that improves the performance of some protocols.
The underlying idea is that a client, which wants to perform several requests,
just transmits those requests in sequence without blocking and waiting for the reply from the server.
In the reference implementation, pipelining is used by the clients of all mini protocol except Chain-Sync.
Those mini protocols follow a request-response pattern that is amenable to pipelining such
that pipelining becomes a feature of the client implementation that does not require any
modifications of the server implementation.

As an example, let's consider the Block-Fetch mini protocol.
When a client follows the protocol and sends a sequence of \RequestRange~messages to the server
the data stream from the client to the server will only consist of \RequestRange~messages
(and a final \ClientDone~message) and no other message types.
The server can simply follow the state machine of the protocol and process the messages in turn,
regardless whether the client uses pipelining or not.
The MUX/DEMUX layer (Section~\ref{multiplexing-section}) guarantees
that messages of the same mini protocol are delivered in transmission order,
and therefore the client can determine which response belongs to which request.

The MUX/DEMUX layer also provides a fixed size buffer between the egress of DEMUX and the ingress
of mini protocol thread.
The size of this buffer is a protocol parameter that determines how many messages
a client can send before waiting for a reply from the server (see Section~\ref{mux-flow-control}).
The protocol requires that a client must never cause a overrun of these buffers on a server node.
If a message arrives at the server that would cause the buffer to overrun,
the server treats this case as a protocol violation of the peer
(and closes the connection to the peer).
\hide{
The buffer sizes are listed in Table~\ref{bla} in Section~\ref{blub}.
}
\section{DeltaQ Mini Protocol}
\wip{
  WIP : Explain DeltaQ measurement back pressure and how we deal with slow connection.
  See Section % ~\ref{deltaq-discussion}.
The DeltaQ mini protocol does not transmit is own messages.
Instead it relies on the time stamps that the multiplexing layer (Section~\ref{multiplexing-section}) adds
to the messages of other mini protocols.
}

\chapter{Connection Management}
\label{connection-management}

\section{The Multiplexing Layer}
\label{multiplexing-section}
Multiplexing is used to run several mini protocols in parallel over a single
channel (for example a single TCP connection).
Figure~\ref{mux-diagram} shows an example of two nodes, each running three
mini protocols and a multiplexer/de-multiplexer.
All the data that is transmitted between the nodes passes through the MUX/DEMUX of the nodes.
There is a fixed pairing of the mini protocol instances, i.e. each mini protocol instance only
communicates with its dual instance.

\begin{figure}[ht]
\pgfdeclareimage[height=5cm]{mux-diagram}{figure/mux-diagram.pdf}
\begin{center}
\pgfuseimage{mux-diagram}
\end{center}
\caption{Data flow though the multiplexer and de-multiplexer}
\label{mux-diagram}
\end{figure}

The implementation of the mini protocol also handles the serialisation and de-serialisation of its messages.
The mini protocols write chunks of bytes to the MUX and read chunks of bytes from the DEMUX.
The MUX reads the data from the mini protocols, splits the data into segments, adds a segment header
and transmits the segments to the DEMUX of its peer.
The DEMUX uses the segment's headers to reassemble the byte streams for the mini protocols on its side.
The multiplexing protocol itself is completely agnostic to the structure of the multiplexed data.

\subsection{Wire Format}
\hsref{ouroboros-network/src/Ouroboros/Network/Mux/Egress.hs}
\begin{table}[ht]
\centering
\begingroup
\setlength{\tabcolsep}{3pt}
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|}
  \hline
  0&1&2&3&4&5&6&7&8&9&0&1&2&3&4&5&6&7&8&9&0&1&2&3&4&5&6&7&8&9&0&1 \\ \hline
  \multicolumn{32}{|c|}{Transmission Time} \\ \hline
  \multicolumn{1}{|c|}{$M$}
  &\multicolumn{15}{|c|}{Mini Protocol ID}
  &\multicolumn{16}{|c|}{Payload-length $n$} \\ \hline
  \multicolumn{32}{|c|}{} \\
  \multicolumn{32}{|c|}{Payload of $n$ Bytes} \\
  \multicolumn{32}{|c|}{} \\ \hline
\end{tabular}
\endgroup
\caption{Multiplexing-segments}
\label{segment-header}
\end{table}

Table~\ref{segment-header} shows the layout of the data segments of the multiplexing protocol
(big-endian bit order).
The segment header contains the following data:
\begin{description}
\item[Transmission Time]
  The transmission time is a time stamp based the wall clock of the peer with a
  resolution of one microsecond.
\item[Mini Protocol ID] The unique ID of the mini protocol as in Table~\ref{mini-protocol-id}.
\item[Payload Length] The payload length is the size of the segment payload in Bytes.
  The maximum payload length that is supported by the multiplexing wire format is $2^{16}-1$.
  Note, that an instance of the protocol can choose a smaller limit for the size of segments it transmits.
\item[Mode] The single bit $M$ (the mode) is used to distinct the dual instances of a mini protocol.
  The mode is set to $0$ in segments from the initiator, i.e. the side that initially has agency and
  $1$ in segments from the responder.
\end{description}

\subsection{Fairness and Flow-Control in the Multiplexer}
The Shelley network protocol requires that the multiplexer uses a fair scheduling of the mini protocols.

The reference Haskell implementation of multiplexer uses a round-robin-schedule of the mini protocols
to choose the next data segment to transmit.
If a mini protocol does not have new data available when it is scheduled, it is skipped.
A mini protocol can transmit at most one segment of data every time it is scheduled
and it will only be rescheduled immediately if no other mini protocol has data available.
Each mini protocol is implemented as a separate Haskell thread.
These threads can signal the multiplexer at any time that they have new data available.

From the point of view of the mini protocols, there is a one-message buffer between the egress of
the mini protocol and the ingress of the multiplexer.
The mini protocol will block when it sends a message and the buffer is full.

A concrete implementation of a multiplexer may use a variety of data structures and heuristics to
yield the overall best efficiency.
For example, although the multiplexing protocol itself is agnostic to the underlying structure of
the data, the multiplexer may try to avoid spliting small mini protocol messages into two segments.
The multiplexer may also try to merge multiple messages from one mini protocol into a
single segment.
Note that, the messages within a segment must all belong to the same mini protocol.

\subsection{Flow-control and Buffering in the Demultiplexer}
\label{mux-flow-control}
The demultiplexer eagerly reads data from its ingress.
There is a fixed size buffer between the egress of the demultiplexer and the ingress of
the mini protocols.
Each mini protocol implements its own mechanism for flow control which guaranties that this buffer
never overflows (See Section~\ref{pipelining}.).
If the demultiplexer detects an overflow of the buffer, it means that the peer violated the
protocol and the MUX/DEMUX layer shuts down the connection to the peer.

\hide{
The size of the buffers is listed in Table~\ref{demux-buffers}.
}

\section{Setup, Shutdown and Management of Connections}
\label{peer-setup-section}
In addition to the exchange of blocks and transactions, as required by Ouroboros,
the network layer also handles several administrative tasks.
This section describes the parts of the protocol that deal with setting up, shutting down and
managing a connection between two peers.
In this section, we use the term {\bf connection} or {\bf bearer} for the multiplexing-layer object
that manages the mini protocol threads, the buffers and the OS-level connection
(for example TCP socket) that deals with one peer of the node.

The multiplexing layer (Section~\ref{multiplexing-section}) is the central crossing between
the mini protocols and the network channel.
Therefore, the reference implementation takes the approach
of implementing the functions for connection management in the same part of the source code
that also implements the multiplexing layer itself.

This section describes the protocol and sketches a possible implementation.
Roughly the implementation performs the following tasks:
\begin{itemize}
\item Open a socket/ acquire resources from the OS.
\item Negotiate the protocol version with the handshake mini protocol
      (Section \ref{handshake-protocol}.
\item Spawn the threads that run the mini protocols.
\item Measure transmission times and amount of in-flight data.
\item Catch exceptions that are thrown by the mini protocols.
\item Shutdown the connection in case of an error.
\item Handle a shutdown request from the peer.
\item Shutdown the threads that run the mini protocols.
\item Close Socket/ free resources.
\end{itemize}

\newcommand{\Larval}{\state{Larval}}
\newcommand{\Connected}{\state{Connected}}
\newcommand{\Mature}{\state{Mature}}
\newcommand{\Dying}{\state{Dying}}
\newcommand{\Dead}{\state{Dead}}

\section{Life Cycle of a Connection}
\begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=1.5cm, semithick]
  \tikzstyle{every state}=[fill=red,draw=none,text=white]
  \node[state, initial]                           (Larval)       {\Larval};
  \node[state, below of=Larval]                   (Connected)    {\Connected};
  \node[state, below of=Connected]                (Mature)       {\Mature};
  \node[state, below of=Mature]                   (Dying)        {\Dying};
  \node[state, below of=Dying]                    (Dead)         {\Dead};
  \draw (Larval)            edge[]      node{OS connect}         (Connected);
  \draw (Connected)         edge[]      node{agree protocol versions, start mini protocols}    (Mature);
  \draw (Mature)         edge[]      node{termination of any mini protocol}           (Dying);
  \draw (Dying)         edge[]      node{transmission of messages that are already buffered,OS disconnect}
         (Dead);
\end{tikzpicture}

A connection passes through several stages during its life cycle.
\begin{description}
\item[\Larval]    The connection exists but nothing has been initialised yet.
\item[\Connected] The OS-level primitives (sockets or pipes) are connected.
\item[\Mature] The mini protocols are running.
\item[\Dying]  One of the mini protocols has terminated.
\item[\Dead] The connection has been terminated.
\end{description}

\newcommand{\InitReq}{\msg{InitReq}}
\newcommand{\InitRsp}{\msg{InitRsp}}
\newcommand{\InitFail}{\msg{InitFail}}

\noindent\hsref{ouroboros-network/src/Ouroboros/Network/Mux/Types.hs}
\newline\hsref{ouroboros-network/src/Ouroboros/Network/NodeToNode.hs}
\newline\hsref{ouroboros-network/src/Ouroboros/Network/NodeToClient.hs}
\hide{Update needed !}
\begin{table}[ht]
\centering
\begin{tabular}{|l|l|l|l|}
  \hline
  ID & Mini Protocol                         & NtN  & NtC \\ \hline
  0  & MUX-Control                           & Yes  & Yes \\ \hline
  1  & DeltaQ                                & Yes  & Yes \\ \hline
  2  & Chain-Sync instantiated to headers    & Yes  & No \\ \hline
  3  & Block-Fetch                           & Yes  & No  \\ \hline
  4  & Transaction-Submission                & No   & Yes  \\ \hline
  5  & Chain-Sync instantiated to blocks     & No   & Yes  \\ \hline
\end{tabular}
\caption{Mini Protocol IDs}
\label{mini-protocol-id}
\end{table}

\subsection{Default Mini Protocol Sets for Node-to-Node and Node-to-Client}
Table~\ref{mini-protocol-id} show which mini protocols are enabled for node-to-node
and node-to-client communication.
Mux-Control and DeltaQ are enabled for all connections.
The communication between two full nodes (NtN) is fully symmetric.
Both nodes run initiator and responder instances of the
Chain-Sync, the Block-Fetch and the Transaction-Submission protocol.
Node-to-Client (NtC) is a connection between a full node and a client that does not take part in
Ouroboros protocol itself and only consumes data, for example a wallet or a block chain explorer.
In a NtC setup, the node only runs the producer side of the Chain-Sync protocol
and the client only the consumer side.
The Chain-Sync protocol is polymorphic in the type of blocks that are transmitted.
NtN uses a Chain-Sync instance which only transmits block headers, while the NtC instance transmits
full blocks.
The two variants of Chain-Sync use different protocol IDs.

% Ping Pong ?
%
\wip{
\subsection{Time Measurement}
}

\subsection{Error Handling}
When a mini protocol thread detects that a peer violates the mini protocol it throws an exception.
The MUX-layer catches the exceptions from the mini protocol threads and shuts down the connection.

\subsection{Data Flow and Isometric Flow Control}
Efficient data flow control is a key aspect of the design of the network layer.
The section gives an overview of the flow of information
from the producer of the information inside a node to the consumer of that piece
of information in an other node in the current implementation.

The section also describes how the network layer guaranties isometric flow control.
The basic idea of isometric flow control is to actively control and limit how much data
can be in-flight between a data producer and a consumer at any moment.
Flow control is an essential consideration that affects every part of the source code
but unlike the state machines of the mini protocols,
that have a direct implementation in the source files,
there is no explicit representation of the flow control in the source.

To explain the flow of information we use the example of a new block created by the consensus layer.
There are many entities and concepts involved:
\begin{description}
\item[Threads]
  Haskell lightweight threads.
\item[Buffers (Haskell)]
  Shared-mutable state, single element buffers, FIFO queues
\item[Lazy evaluation]
\item[Functioncalls]
  Synchronous/blocking, asynchronous
\item[Haskell RTS]
  Manages the Haskell threads and maps Haskell threads to OS threads.
  Wakes up threads that are blocked waiting for specific events.
\item[OS Network Stack]
  Manages OS-level buffers.
\item[IP network]
todo: draw diagram
mention: back pressure, head of line blocking  
\end{description}
  
\hide{
\chapter{Peer Discovery and Peer Selection}
\wip{
  Peer discovery and peer selection are relatively independent for the core components of a node.
  In a first iteration, it may be enough to specify what data is going from
  the peer selection algorithm to
  the core components and what data is going from the core components to the peer selection.
  Also peer discovery and peer selection are relatively independent from each other.
  }

\chapter{Infrastructure}
\label{infrastructure}
\wip{
  WIP: Specific assumptions about the infrastructure that are relevant for the discussion.
}

\section{Internet}
\section{Network Topology}
\section{DNS,NTP}
\section{Topographical distribution of block creating nodes}
\section{TCP}
\section{IP}
MTU
\section{Operating Systems}
\section{Firewall}
\section{Nodes and Hosting}
}

\hide{
\chapter{Haskell}
While the network protocol itself can be implemented in many programming languages,
it has been developed in parallel with a Haskell reference implementation.
In addition to the language agnostic protocol description in the other parts of this document,
this section discusses key aspects of the Haskell implementation.
This section is most useful for people who work with the Haskell reference implementation and
may give some extra insights for anybody who is interested in implementing the
network component.
For understanding the protocol, it is save to skip this section.
\section{Constant Memory Consumption}
\section{The State Machine Framework}
\label{Haskell-state-machine}
}

\hide{
\chapter{Discussion}
\section{Related Work}
\subsection{Other Crypto Currencies}
\subsubsection{PoW Systems}
\subsubsection{PoS Systems}
\subsection{Generic Peer to Peer Systems}
\subsection{Formal Correctness}
}
\wip{
  The correctness of distributed and concurrent systems has been studied intensively for decades.
\begin{description}
\item [Safety properties]
  Prove that a bad thing will never happen.
  \begin{itemize}
  \item Coins cannot be stolen
  \item Preservation of Money
  \item Nodes will not run out of Memory
  \item (Property: Current state is valid) will always hold / never fail
  \end{itemize}
\item[Liveness properties]
  Prove that a desired event will happen.
  \begin{itemize}
  \item Message will be delivered
  \item Consensus will be reached
  \item Transaction will be confirmed
  \item Fairness : the desired event will happen in time. One does not have to wait forever
  \item Starvation
  \item Deadlocks
  \end{itemize}
\item[Temporal logic]
  Tailor made logic for analysing concurrent systems.
  \begin{itemize}
  \item Argue about the temporal order of events in transition systems.
  \item Express safety properties.
  \item Express liveness properties.
  \item Express Fairness.
  \item Prove with model checkers.
  \item Refinement properties.
  \item CTL computation tree logic (safety)
  \item LTL linear time logic (fairness)
  \end{itemize}
\item[Time]
  How does a concurrent system deal with time ?
  \begin{itemize}
  \item Physical clocks / Wall clock time
  \item Logical clocks / Vector clocks / order of events
  \item Order of events : Before , Concurrent, After
  \item Hybrid approaches, Ouroboros, slot-times
  \end{itemize}
\item[Session Types]
     Model protocols and transition systems in a type system.
\item[Pi-calculus]
\item[Process algebras]
\end{description}
}
\hide{
\wip{WIP: Poldercast,etc}
\section{Overview}
}
\section{Design Discussion}
\subsubsection{Why distinguish between node to node and node-to-consumer IPC}
\label{why_distinguish_protocols}
We use two different sets of protocols for these two use cases.

\begin{description}
\item[node-to-node] IPC between nodes that are engaged in the high level Ouroboros
      blockchain consensus protocol.
\item[node-to-consumer] IPC between a Cardano node and a `chain consumer' component such as a
      wallet, explorer or other custom application.
\end{description}

This section describes the differences between those two variants of IPC and why they use
different protocols.

The node-to-node protocol is conducted in a P2P environment
with very limited trust between peers. The node-to-node protocol utilises
store-and-forward over selected \emph{bearers} which form the underlying
connectivity graph. A concern in this setting is asymmetric resource
consumption attacks. Ease of implementation is desirable, but is
subordinate to the other hard constraints.

A node-to-consumer protocol is intended to support blockchain applications
like wallets and explorers, or Cardano-specific caches or proxies. The setting
here is that a consumer trusts a node (a `chain producer') and just wants to
catch up and keep up with the blockchain of that producer. It is assumed that
a consumer only consumes from one producer (or one of a related set of
producers), so unlike in the node-to-node protocol there is no need to choose
between different available chains. The producer may still not fully trust the
consumer and does not want to be subject to asymmetric resource
consumption attacks. In this use case, because of the wider range of
applications that wish to consume the blockchain, having some options that are
easy to implement is more important, even if this involves a trade-off with
performance. That said, there are also use cases where tight integration is
possible and making the most efficient use of resources is more desirable.

There are a number of applications that simply want to consume the blockchain,
but are able to rely on an upstream trusted or semi-trusted Cardano consensus
node. These applications do not need to engage in the full consensus protocol,
and may be happy to delegate the necessary chain validation.

Examples include 3rd party applications that want to observe the blockchain,
examples being business processes triggered by transactions or analytics.  It
may also include certain kinds of light client that wish to follow the
blockchain but not do full validation.

Once one considers a node-to-consumer protocol as a first class citizen then it
opens up opportunities for different system architecture choices.
The architecture of the original Cardano Mainnet release was entirely homogeneous:
every node behaved the same, each trusted nothing but itself and paid the full
networking and processing cost of engaging in the consensus protocol.  In
particular everything was integrated into a single process: the consensus
algorithm itself, serving data to other peers and components such as the wallet
or explorer. If we were to have a robust and efficient node-to-consumer protocol
then we can make many other choices.

With an efficient \emph{local} IPC protocol we can have applications
like wallets and explorers as separate processes. Even for tightly
integrated components it can make sense to run them in separate OS
processes and using associated OS management tools. Not only are the
timing constraints for a consensus node much easier to manage when
it does not have to share CPU resources with chain consumers,
but it enables sophisticated end-users to use operating system features
to have finer control over resource consumption.
There have been cases in production where a highly loaded wallet component takes
more than its allowed allocation of CPU resources and causes the local
node to miss its deadlines.  By giving a consensus node a dedicated
CPU core it becomes easier to provide the necessary hard real
time guarantees. In addition, scaling on multi-core machines is
significantly easier with multiple OS processes than with a
multi-threaded OS process with a shared-heap. This could allow
larger capacity Cardano relay deployments where there are multiple
network facing proxy processes that all get their chain from a single
local consensus node.

With an efficient \emph{network} IPC protocol we can do similar things
but extend it across multiple machines. This permits: large
organisations to achieve better alignment with their security
policies; clusters of relays operated by a single organisation to use
the more efficient (less resource costly) node-to-consumer protocol
instead of the node-to-node protocol; and wallet
or explorer-like applications that need to scale out, and are able to
make use of a trusted node.

\hide{
\section{Requirements}
\section{Threat Vectors}
\wip{
\begin{description}
\item [Generic Attacks against IP networks]
\item [Attacks against a specific implementation of the protocol]
\item [Attacks against a specific configuration of the system]
\item [Attacks against the network protocol itself]
\item [Attacks against Ouroboros]
\item [Clever combinations of the above]
\end{description}
}
\subsubsection{Asymptotic Resource Consumption}
\section{Results from Simulations}
\section{Pub Sub}
\section{Of the Shelf Protocols}
\section{Congestion Control}
\subsection{DeltaQ and Back-pressure}
\label{deltaq-discussion}
\wip{WIP: discuss DeltaQ and Back-pressure}

\section{Meta Requirements}
\subparagraph{Work in Progress}
This document is evolved in parallel with the work on the protocol design and
the reference implementation.

\subparagraph{The Document should be Comprehensive}
\begin{itemize}
\item Top down approach.
\item Provide the big picture.
\item Usable as a reference point for a broader discussion.
\item Cover every aspect that is related to network connections.
\item Every aspect should at least have a place in the table of contents.
  If there are holes and parts that are not covered the document should say what is missing.
\item Stand alone readable with links to where missing pieces can be found.
\end{itemize}

\subparagraph{Detailed}
\begin{itemize}
\item Sufficient details to allow for new independent implementations that are compatible with
the reference implementation
\item Language agnostic (it is save to skip the Haskell specific parts)
\item Design discussions
\end{itemize}
\subparagraph{Structured}
\begin{itemize}
\item Parts of the document should be in a logical connection
\end{itemize}
\subparagraph{Workflow}
}

\appendix
\chapter{CDDL Specification of the Protocol Messages}
\label{CBOR-section}
\hsref{ouroboros-network/src/Ouroboros/Network/Protocol/PingPong/Codec.hs}
\label{included-cddl}
This Sections contains the CDDL\cite{cddl} specification
of the binary serialisation format of the network protocol messages.

To keep this Section in close sync with the actual Haskell implementation
the names of the Haskell identifiers have been reused for the corresponding
CBOR types (with the first letter converted to lower case).
Note, that, for readability, the previous Sections used simplified message identifiers,
for example {\tt RequestNext} instead of {\tt msgRequestNext}, etc.
Both identifiers refer to the same message format.

All transmitted messages satisfy the shown CDDL specification.
However, CDDL, by design, also permits variants in the encoding that are not valid in the protocol.
In particular, the notation ${\tt [} ... {\tt ]}$ in CDDL can be used for both fixed-length
and variable-length CBOR-list, while only one of the two encodings is valid in the protocol.
We add comments in specification to make clear which encoding must be used.

Note that, in the case of the request-response mini protocol (Section~ref{request-response-protocol})
there in only ever one possible kind of message in each state.
This means that there is no need to tag messages at all
and the protocol can directly transmit the plain request and response data.

\wip{TODO: test that haskell(message) => cddl(message) }
\lstinputlisting{messages.cddl.incl}
\bibliographystyle{apalike}
\bibliography{references}

\hide{
\chapter{Key Figures of the Protocol and the P2P Network}
This section list some key figures of the network protocol.
There is a variety of figures that quantify some aspects of the protocol, for example:
\begin{itemize}
\item Configuration parameters that are explicitly set in the protocol.
\item Requirements and performance targets.
\item Implicit assumptions about about network bandwidths, etc.
\item Estimates from simulations and game theoretic results.
\end{itemize}
These figures can be a fixed value, a possible interval, a distribution of values,
or just a rough estimate and typically these figures depend on each other.
The figures in this section are not set in stone, but they should help to give a baseline that helps
to understand the protocol design.

Block chain parameters:\\
\begin{tabular}{p{4cm}p{1cm}p{6cm}p{1cm}} \hline
  maximum block size   & = & 2 M Bytes                                    &  \\ \hline
  slot time            & = & 20s                                          &  \\ \hline
  epoch length         & = & 22600 slots $\simeq$ 5 days                  &  \\ \hline
  intrinsic probability of a fork & = &                                   &  \\ \hline
  K parameter (maximal roll back) & = &                                   &  \\ \hline
\end{tabular}\\

Transaction:\\
\begin{tabular}{p{4cm}p{1cm}p{6cm}p{1cm}} \hline
  size of a transaction                & = &  some K Bytes               &  \\ \hline
  through-put transactions per second   & = &  15                        &  \\ \hline
\end{tabular}\\

Network topology:\\
\begin{tabular}{p{4cm}p{1cm}p{6cm}p{1cm}} \hline
  maximum hops                         & $\le$ &  5                         &  \\ \hline
  maximum number of neighbours          & = &  5                         &  \\ \hline
\end{tabular}

\begin{tabular}{p{4cm}p{1cm}p{6cm}p{1cm}} \hline
  bandwidth stake pool                             & = &  > 100Mbit/s             &  \\ \hline
  bandwidth small stake holder                    & = &  ~ 100Mbit/s             &  \\ \hline
  bandwidth none staking chain consumer          & = &  5                       &  \\ \hline
  latency  between stake pool nodes                & <10 ms                       &  \\ \hline
\end{tabular}\\


\chapter{Nomenclature}
\begin{description}
\item[Adversary / Adversarial Action]
  acting in way to subvert the correct (or performant) operation of the distributed protocol.
  Note that non-performance of certain functions at appropriate times can
  fall into this category.
\item[Core DIF]
  The set of end points that belong to the (major)
  stakepools; (the term DIF taken from RINA\ref{RINA} where it denotes
  a (potentially closed) set of potential participants.
\item[egress,ingress]
\item[head of line blocking]
\end{description}

