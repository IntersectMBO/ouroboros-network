\chapter{Consensus Protocol}
\label{consensus}

% TODO: what kind of variation does this design support?
% (counter-example: genesis rule)

% TODO: Describe API
%
% TODO: State invariants
%
% TODO: Discuss relationship to the Ouroboros papers. Where are the various parts
% of the paper implemented? How do additional design constraints change this?
% (e.g. header/body split)

\section{Overview}

\subsection{Chain selection}
\label{consensus:overview:chainsel}

Chain selection is the process of choosing between multiple competing chains,
and is one of the most important responsibilities of a consensus protocol. When
choosing between two chains, in theory any part of those chains could be
relevant; indeed, the research literature typically describes chain selection as
a comparison of two entire chains (\cref{bft-paper,praos-paper}). In practice
that is not realistic: the node has to do chain selection frequently, and
scanning millions of blocks each time to make the comparison is of course out of
the question.

The consensus layer keeps the most recent headers as a \emph{chain fragment}
in memory (\cref{storage:inmemory}); the rest of the chain is stored on disk.
Similarly, we keep a chain fragment of headers in memory for every (upstream)
node whose chain we are following and whose blocks we may wish to adopt
(\cref{chainsyncclient}). Before the introduction of the hard fork combinator
chain selection used to be given these fragments to compare; as we will discuss
in \cref{hfc:intro}, however, this does not scale so well to hybrid chains.

It turns out, however, that it suffices to look only at the headers at the very
tip of the chain, at least for the class of consensus algorithms we need to
support. The exact information we need about that tip varies from
one protocol to the other, but at least for the Ouroboros family of consensus
protocols the essence is always the same: we prefer longer chains over shorter
ones (justifying \emph{why} this is the right choice is the domain  of
cryptographic research and well outside the scope of this report). In the
simplest case, the length of the chain is \emph{all} that matters, and hence the
only thing we need to know about the blocks at the tips of the chains is their
block numbers.\footnote{It doesn't actually matter if the actual block headers
contain a block number or not; if they don't, we can add a ``virtual field''
to the in-memory representation of the block header. For block headers that
\emph{do} include a block number (which is the case for the Cardano chain),
header  validation verifies that the block number is increasing. Note that EBBs
complicate this particular somewhat; see page~\pageref{ebb-chain-selection}.}

This does beg the question of how to compare two chains when one (or both) of
them are empty, since now we have no header to compare. We will resolve this by
stating the following fundamental assumption about \emph{all} chain selection
algorithms supported by the consensus layer:

\begin{assumption}[Prefer extension]
\label{prefer-extension}
The extension of a chain is always preferred over that chain.
\end{assumption}

A direct consequence of \cref{prefer-extension} is that a non-empty chain is
always preferred over an empty one,\footnote{Comparing empty chain
\emph{fragments}, introduced in \cref{storage:fragments}, is significantly more
subtle, and will be discussed in \cref{chainsel:fragments}.} but we will
actually need something stronger than that: we insist that shorter chains can
never be preferred over longer ones:

\begin{assumption}[Never Shrink]
\label{never-shrink}
A shorter chain is never preferred over a longer chain.
\end{assumption}

\Cref{never-shrink} does not say anything about chains of equal length; this will
be important for Praos (\cref{praos}). An important side-note here is that
the Ouroboros Genesis consensus protocol includes a chain selection rule
(the genesis rule) that violates \cref{never-shrink} (though not \cref{prefer-extension}); it also cannot be defined by only looking at the tips of chains.
It will therefore require special treatment; we will come back to this in
\cref{genesis}.

\subsection{The security parameter $k$}
\label{consensus:overview:k}

When the Cardano blockchain was first launched, it was using a consensus
protocol that we now refer to as Ouroboros Classic \cite{cryptoeprint:2016:889}.
The re-implementation of the consensus layer never had support for Ouroboros
Classic, instead using Ouroboros BFT \cite{cryptoeprint:2018:1049} as a
transitional protocol towards Ouroboros Praos \cite{cryptoeprint:2017:573},
which is the consensus protocol in use at the time of writing, with plans to
switch to Ouroboros Genesis \cite{cryptoeprint:2018:378} relatively soon
(\cref{genesis}).

Both Ouroboros Classic and Ouroboros Praos are based on a chain selection rule
that imposes a maximum rollback condition: alternative chains to a node's
current chain that fork off more than a certain number of blocks ago are never
considered for adoption. This limit is known as the \emph{security parameter},
and is usually denoted by $k$; at present $k = 2160$ blocks. The Ouroboros
analysis shows that consensus will be reached despite this maximum rollback
limitation; indeed, this maximum rollback is \emph{required} in order to reach
consensus (we discuss this in some detail in
\cref{genesis:background:longest-chain}).

For Ouroboros BFT and Ouroboros Genesis the situation is slightly different:

\begin{itemize}
\item Ouroboros BFT does not impose a maximum rollback, but adding such a
requirement does not change the protocol in any fundamental way: the analysis
for Ouroboros Praos shows that nodes will not diverge more than $k$ blocks, and
since BFT converges much quicker than that, adding this (large) maximum rollback
requirement does not change anything.
\item The analysis that shows that nodes will not diverge by more than $k$
blocks does of course not apply to new nodes joining the system. Indeed, when
using Ouroboros Praos, such nodes are vulnerable to an attack where an adversary
with some stake (does not have to be much) presents the newly joining node with
a chain that diverges by more than $k$ blocks from the honest chain, at which
point point the node would become unable to switch to the real chain. Solving
this is the purview of Ouroboros Genesis.

Like Ouroboros BFT, Ouroboros Genesis likewise does not impose a maximum
rollback, \emph{but} the analysis \cite{cryptoeprint:2018:378} shows that when
nodes are up to date, they can employ the Ouroboros Praos rule (i.e., the rule
\emph{with} the maximum rollback requirement). This is not true when the node is
behind and is catching up, but the main goal of \cref{genesis} is to show how we
can nonetheless avoid rollbacks exceeding $k$ blocks even when a node is
catching up.
\end{itemize}

Within the consensus layer we therefore assume that we \emph{always} have a
limit $k$ on the number of blocks we might have to rollback. We take advantage
of this in many ways; here we just mention a few:

\begin{itemize}
\item We use it as an organising principle in the storage layer
(\cref{storage}), dividing the chain into a part that we know is stable (the
"immutable chain"), and a part near the tip that is still subject to rollback
(the "volatile chain"). Block lookup into the immutable chain is very efficient,
and since the vast majority of the chain is immutable, this helps improve
overall efficiency of the system.

\item When we switch to a new fork by rolling back and then adopting some new
blocks, those new blocks must be verified against the ledger state as it was
at the point we rolled back to. This means we must be able to construct
historical ledger states. In principle this is always possible, as we can always
reply the entire chain, but doing so would be expensive. However, since we have
a limit on the maximum rollback, we also have a limit on how old the oldest
ledger state is we might have to reconstruct; we take advantage of this in the
Ledger Database (\cref{ledgerdb}) which can efficiently reconstruct any of those
$k$ historical ledger states.

\item We need to keep track of the chains of our peer nodes in order to be able
to decide whether or not we might wish to switch to those chains
(\cref{chainsyncclient}). For consensus protocols based on a longest chain rule
(such as Ouroboros Praos), this means that we would need to download and verify
enough blocks from those alternative chains that the alternative chain becomes
longer than our own. Without a maximum rollback, this would be an unbounded
amount of work as well as an unbounded amount of data we would have to store.
A maximum rollback of $k$, however, means that validating (and storing) $k+1$
blocks should be sufficient.\footnote{For chain selection algorithms such as
Ouroboros Genesis which are based on properties of the chains near their
\emph{intersection point} rather than near their tips this is less relevant.}
\end{itemize}

Of course, a maximum rollback may be problematic in the case of severe network
outages that partition the nodes for extended periods of time (in the order of
days). When this happens, the chains will diverge and recovering converge will
need manual intervention; this is true for any of the consensus protocols
mentioned above. This manual intervention is outside the scope of this report.

\section{The \lstinline!ConsensusProtocol! Class}
\label{consensus:class}

We model consensus protocols as a single class called
\lstinline!ConsensusProtocol!; this class can be considered to be the
central class within the consensus layer.

\begin{lstlisting}
class (..) => ConsensusProtocol p where
\end{lstlisting}

The type variable $p$ is a type-level tag describing a particular consensus
protocol; if Haskell had open kinds\footnote{We will come back to this in
\cref{future:openkinds}.}, we could say \lstinline!(p :: ConsensusProtocol)!.
All functions within this class take an argument of type
%
\begin{lstlisting}
data family ConsensusConfig p :: Type
\end{lstlisting}
%
This allows the protocol to depend on some static configuration data; what
configuration data is required will vary from protocol to
protocol.\footnote{Explicitly modelling such a required context could be avoided
if we used explicit records instead of type classes; we will discuss this point
in more detail in \cref{technical:classes-vs-records}.}  The rest of the
consensus layer does not really do much with this configuration, except make it
available where required; however, we do require that whatever the configuration
is, we can extract $k$ from it:
%
\begin{lstlisting}
protocolSecurityParam :: ConsensusConfig p -> SecurityParam
\end{lstlisting}
%
For example, this is used by the chain database to determine when blocks can be
moved from the volatile DB to the immutable DB (\cref{storage:components}). In
the rest of this section we will consider the various parts of the
\lstinline!ConsensusProtocol! class one by one.

\subsection{Chain selection}
\label{consensus:class:chainsel}

As mentioned in \cref{consensus:overview:chainsel}, chain selection will only
look at the headers at the tip of the ledger. Since we are defining consensus
protocols independent from a concrete choice of ledger, however
(\cref{decouple-consensus-ledger}), we cannot use a concrete block or header
type. Instead, we merely say that the chain selection requires \emph{some} view
on headers that it needs to make its decisions:

\begin{lstlisting}
type family SelectView p :: Type
type SelectView p = BlockNo
\end{lstlisting}

The default is \lstinline!BlockNo! because as we have seen this is all that is
required for the most important chain selection rule, simply preferring longer
chains over shorter ones. It is the responsibility of the glue code that
connects a specific choice of ledger to a consensus protocol to define the
projection from a concrete block type to this \lstinline!SelectView!
(\ref{BlockSupportsProtocol}). We then require that these views must be
comparable
%
\begin{lstlisting}
class (Ord (SelectView p), ..) => ConsensusProtocol p where
\end{lstlisting}
%
and say that one chain is (strictly) preferred over another if its
\lstinline!SelectView! is greater. If two chains terminate in headers with
the \emph{same} view, neither chain is preferred over the other, and we
could pick either one (we say they are equally preferable).

Later in this chapter we will discuss in detail how our treatment of
consensus algorithms differs from the research literature (\cref{bft,praos}),
and in \cref{chainsel} we will see how the details of how chain selection
is implemented in the chain database; it is worth pointing out here, however, that the comparison based on \lstinline!SelectView! is not intended to capture

\begin{itemize}
\item chain validity
\item the intersection point (checking that the intersection point is not too
far back, preserving the invariant that we never roll back more than $k$ blocks,
see \cref{consensus:overview:k})
\end{itemize}

Both of these responsibilities would require more than seeing just
the tip of the chains. They are handled independent of the choice of
consensus protocol by the chain database, as discussed in \cref{chainsel}.

When two \emph{candidate} chains (that is, two chains that aren't our current)
are equally preferable, we are free to choose either one. However, when a
candidate chain is equally preferable to our current, we \emph{must} stick
with our current chain. This is true for all Ouroboros consensus protocols,
and we define it once and for all:

\begin{lstlisting}
preferCandidate ::
     ConsensusProtocol p
  => proxy      p
  -> SelectView p  -- ^ Tip of our chain
  -> SelectView p  -- ^ Tip of the candidate
  -> Bool
preferCandidate _ ours cand = cand > ours
\end{lstlisting}

\subsection{Ledger view}
\label{consensus:class:ledgerview}

We mentioned in \cref{overview:ledger} that some consensus protocols may require
limited information from the ledger; for instance, the Praos consensus protocol
needs access to the stake distribution for the leadership check. In the
\lstinline!ConsensusProtocol! abstraction, this is modelled as a \emph{view}
on the ledger state

\begin{lstlisting}
type family LedgerView p :: Type
\end{lstlisting}

The ledger view will be required in only one function: when we ``tick'' the
state of the consensus protocol. We will discuss this state management in more
detail next.

\subsection{Protocol state management}
\label{consensus:class:state}

Each consensus protocol has its own type chain dependent state\footnote{We are
referring to this as the ``chain dependent state'' to emphasise that this is
state that evolves with the chain, and indeed is subject to rollback when we
switch to alternatives forks. This distinguishes it from chain
\emph{independent} state such as evolving private keys, which are updated
independently from blocks and are not subject to rollback.}

\begin{lstlisting}
type family ChainDepState p :: Type
\end{lstlisting}

The state must be updated with each block that comes in, but just like for
chain selection, we don't work with a concrete block type but instead define a
\emph{view} on blocks that is used to update the consensus state:

\begin{lstlisting}
type family ValidateView p :: Type
\end{lstlisting}

We're referring to this as the \lstinline!ValidateView! because updating the
consensus state also serves as \emph{validation} of (that part of) the block;
consequently, validation can also \emph{fail}, with protocol specific error
messages:

\begin{lstlisting}
type family ValidationErr p :: Type
\end{lstlisting}

Updating the chain dependent state now comes as a pair of functions. As for the ledger
(\cref{overview:ledger}), we first \emph{tick} the protocol state to the
appropriate slot, passing the already ticked ledger view as an
argument:\footnote{Throughout the consensus layer, the result of ticking is
distinguished from the unticked value at the type level. This allows to store
additional (or indeed, less) information in the ticked ledger state, but also
clarifies ordering. For example, it is clear in \lstinline!tickChainDepState!
that the ledger view we pass as an argument is already ticked, as opposed to the
\emph{old} ledger view.}

\begin{lstlisting}
tickChainDepState ::
     ConsensusConfig p
  -> Ticked (LedgerView p)
  -> SlotNo
  -> ChainDepState p
  -> Ticked (ChainDepState p)
\end{lstlisting}

As an example, the Praos consensus protocol (\cref{praos}) derives its
randomness from the  chain itself. It does that by maintaining a set of random
numbers called \emph{nonces}, which are used as seeds to pseudo-random number
generators. Every so often the current nonce is swapped out for a new one; this
does not depend on the specific block, but merely on a certain slot number being
reached, and hence is an example of something that the ticking function should
do.

The (validation view on) a block can then be applied to the already ticked
protocol state:

\begin{lstlisting}
updateChainDepState ::
     ConsensusConfig       p
  -> ValidateView          p
  -> SlotNo
  -> Ticked (ChainDepState p)
  -> Except (ValidationErr p) (ChainDepState p)
\end{lstlisting}

Finally, there is a variant of this function that can we used to \emph{reapply}
a known-to-be-valid block, potentially skipping expensive cryptographic checks,
merely computing what the new state is:

\begin{lstlisting}
reupdateChainDepState ::
     ConsensusConfig       p
  -> ValidateView          p
  -> SlotNo
  -> Ticked (ChainDepState p)
  -> ChainDepState         p
\end{lstlisting}

Re-applying previously-validated blocks happens when we are replaying blocks
from the immutable database when initialising the in-memory ledger state
(\cref{ledgerdb:on-disk:initialisation}). It is also useful during chain
selection (\cref{chainsel}): depending on the consensus protocol, we may end up
switching relatively frequently between short-lived forks; when this happens,
skipping expensive checks can improve the performance of the node. \todo{How
  does this relate to the best case == worst case thing? Or to the asymptotic
  attacker/defender costs?}

\subsection{Leader selection}
\label{consensus:class:leaderselection}

The final responsibility of the consensus protocol is leader selection. First,
it is entirely possible for nodes to track the blockchain without ever producing
any blocks themselves; indeed, this will be the case for the majority of
nodes\footnote{Most ``normal'' users will not produce blocks themselves, but
instead delegate their stake to stakepools who produce blocks on their behalf.}
In order for a node to be able to lead at all, it may need access to keys and
other configuration data; the exact nature of what is required is different
from protocol to protocol, and so we model this as a type family

\begin{lstlisting}
type family CanBeLeader p :: Type
\end{lstlisting}

A value of \lstinline!CanBeLeader! merely indicates that the node has the
required configuration to lead at all. It does \emph{not} necessarily mean that
the node has the right to lead in any particular slot; \emph{this} is indicated
by a value of type \lstinline!IsLeader!:

\begin{lstlisting}
type family IsLeader p :: Type
\end{lstlisting}

In simple cases \lstinline!IsLeader! can just be a unit value (``yes, you are a
leader now'') but for more sophisticated consensus protocols such as Praos this
will be a cryptographic proof that the node indeed has the right to lead in this
slot. Checking whether a that \emph{can} lead \emph{should} lead in a given slot
is the responsibility of the final function in this class:

\begin{lstlisting}
checkIsLeader ::
     ConsensusConfig       p
  -> CanBeLeader           p
  -> SlotNo
  -> Ticked (ChainDepState p)
  -> Maybe (IsLeader       p)
\end{lstlisting}

\section{Connecting a block to a protocol}
\label{BlockSupportsProtocol}

Although a single consensus protocol might be used with many blocks, any given
block is designed for a \emph{single} consensus protocol. The following type
family witnesses this relation:\footnote{For a discussion about why we
choose to make some type families top-level definitions rather than associate
them with a type class, see \cref{technical:toplevel-vs-associated}.}
%
\begin{lstlisting}
type family BlockProtocol blk :: Type
\end{lstlisting}
%
Of course, for the block to be usable with that consensus protocol, we need
functions that construct the \lstinline!SelectView!
(\cref{consensus:class:chainsel}) and \lstinline!ValidateView!
(\cref{consensus:class:state}) projections from that block:
%
\begin{lstlisting}
class (..) => BlockSupportsProtocol blk where
  validateView ::
       BlockConfig blk
    -> Header blk -> ValidateView (BlockProtocol blk)

  selectView ::
       BlockConfig blk
    -> Header blk -> SelectView (BlockProtocol blk)
\end{lstlisting}
%%
The \lstinline!BlockConfig! is the static configuration required to work with
blocks of this type; it's just another data family:
%
\begin{lstlisting}
data family BlockConfig blk :: Type
\end{lstlisting}

\section{Design decisions constraining the Ouroboros protocol family}
\label{design-decisions-constraining-ouroboros}

\todo{TODO} TODO: Perhaps we should move this to conclusions; some of these
requirements may only become clear in later chapters (like the forecasting
range).

\todo{TODO} TODO: The purpose of this section should be to highlight design
decisions we're already covering in this chapter that impose constraints
on existing or future members of the Ouroboros protocol family.

For example, we at least have:
\begin{itemize}
\item max-K rollback, we insist that there be a maximum rollback length. This
was true for Ouroboros Classic, but is not true for Praos/Genesis, nevertheless
we insist on this for our design. We should say why this is so helpful for our
design. We should also admit that this is a fundamental decision on liveness vs
consistency, and that we're picking consistency over liveness. The Ouroboros
family is more liberal and different members of that family can and do make
different choices, so some adaptation of protocols in papers may be needed to
fit this design decision. In particular this is the case for Genesis. We cannot
implement Genesis as described since it is not compatible with a rollback limit.

\item We insist that we can compare chains based only on their tips. For example
even length is a property of the whole chain not a block, but we insist that
chains include their length into the blocks in a verifiable way, which enables
this tip-only checking. Future Ouroboros family members may need some adaptation
to fit into this constraint. In particular the Genesis rule as described really
is a whole chain thing. Some creativity is needed to fit Genesis into our
framework: e.g. perhaps seeing it not as a chain selection rule at all but as a
different (coordinated) mode for following headers.

\item We insist that a strict extension of a chain is always preferred over
that chain.

\item We insist that we never roll back to a strictly shorter chain.

\item The minimum cyclic data dependency time: the minimum time we permit
between some data going onto the chain and it affecting the validity of blocks
or the choices made by chain selection. This one is a constraint on both the
consensus algorithm and the ledger rules. For example this constrains the Praos
epoch structure, but also ledger rules like the Shelley rule on when genesis
key delegations or VRF key updates take effect. We should cover why we have this
constraint: arising from wanting to do header validation sufficiently in advance
of block download and validation that we can see that there's a potential longer
valid chain.

\item The ledger must be able to look ahead sufficiently to validate $k + 1$
headers (to guarantee a roll back of $k$). \todo{TODO}TODO: We should discuss
this in more detail.
\end{itemize}

\section{Permissive BFT}
\label{bft}

Defined in \cite{byron-chain-spec}
Not to be confused with ``Practical BFT'' \cite{10.1145/571637.571640}

\subsection{Background}
\label{bft:background}

\duncan
Discuss \emph{why} we started with Permissive BFT (backwards compatible with
Ouroboros Classic).

\subsection{Implementation}

\subsection{Relation to the paper}
\label{bft-paper}

Permissive BFT is a variation on Ouroboros BFT, defined in
\cite{cryptoeprint:2018:1049}. We have included the main protocol description
from that paper as \cref{figure:bft} in this document; the only difference is
that we've added a few additional labels so we can refer to specific parts of
the protocol description below.

It will be immediately obvious from \cref{figure:bft} that this description
covers significantly more than what we consider to be part of the consensus
protocol proper here. We will discuss the various parts of the BFT protocol
description below.

\begin{description}
  \item[Clock update and network delivery] The BFT specification requires that
  ``with each advance of the clock (..) a collection of transactions and
  blockchains are pushed to the server''. We consider neither block submission
  nor transaction submission to be within the scope of the consensus algorithm;
  see \cref{nonfunctional:network:blocksubmission,servers:blockfetch} and
  \cref{nonfunctional:network:blocksubmission,servers:txsubmission} instead, respectively.

  \item[Mempool update] (\cref{bft:mempool}). The design of the mempool is the
  subject of \cref{mempool}. Here we only briefly comment on how it relates to
  what the BFT specification assumes:
%
  \begin{itemize}
    \item \textit{Consistency} (\cref{bft:mempool:consistency}). Our mempool
    does indeed ensure consistency. In fact, we require something strictly
    stronger; see \cref{mempool:consistency} for details.
    \item \textit{Time-to-live (TTL)} (\cref{bft:mempool:ttl}). The BFT
    specification requires that transactions stay in the mempool for a maximum
    of $u$ rounds, for some configurable $u$. Our current mempool does not have
    explicit support for a TTL parameter. The Shelley ledger will have support
    for TTL starting with the ``Allegra'' era, so that transactions are only
    valid within a certain slot window; this is part of the normal ledger rules
    however and requires no explicit support from the consensus layer. That's
    not to say that explicit support would not be useful; see \cref{future:ttl}
    in the chapter on future work.
    \item \textit{Receipts} (\cref{bft:mempool:receipts}). We do not offer any
    kind of receipts for inclusion in the mempool. Clients such as wallets must
    monitor the chain instead (see also \cite{wallet-spec}). The BFT
    specification marks this as optional so this is not a deviation.
  \end{itemize}
%
  \item[Blockchain update] (\cref{bft:update}). The BFT specification requires
  that the node prefers any valid chain over its own, as long as its strictly
  longer. \emph{We do not satisfy this requirement.} The chain selection rule
  for Permissive BFT is indeed the longest chain rule, \emph{but} consensus
  imposes a global maximum rollback (the security parameter $k$;
  \cref{consensus:overview:k}). In other words, nodes \emph{will} prefer longer
  chains over its own, \emph{provided} that the intersection between that chain
  and the nodes own chain is no more than $k$ blocks away from the node's tip.
  \todo{Justify this maximum rollback?}

  Moreover, our definition of validity is also different. We do require that
  hashes line up (\cref{bft:update:hash}), although we do not consider this part
  of the responsibility of the consensus protocol, but instead require this
  independent of the choice of consensus protocol when updating the header state
  (\cref{storage:headerstate}). We do of course also require that the transactions in
  the block are valid (\cref{bft:update:body}), but this is the responsibility
  of the ledger layer instead (\cref{ledger}); the consensus protocol should be
  independent from what's stored in the block body.

  Permissive BFT is however different from BFT \emph{by design} in the
  signatures we require.\footnote{\label{footnote:singlesignature}There is
  another minor deviation from the specification: we don't require an explicit
  signature on the block body. Instead, we have a single signature over the
  header, and the header includes a \emph{hash} of the body.} BFT requires that
  each block is signed strictly according to the round robin schedule
  (\cref{bft:update:signatures}); the whole point of \emph{permissive} BFT is
  that we relax this requirement and merely require that blocks are signed by
  \emph{any} of the known core nodes.

  Permissive BFT is however not \emph{strictly} more permissive than BFT:
  although blocks do not need to be signed according to the round robin
  schedule, there is a limit on the number of signatures by any given node in a
  given window of blocks. When a node exceeds that threshold, its block is
  rejected as invalid. Currently that threshold is set to 0.22 \cite[Appendix A,
  Calculating the $t$ parameter]{byron-chain-spec}, which was considered to be
  the smallest value that would be sufficiently unlikely to consider a chain
  generated by Ouroboros Classic as invalid (\cref{bft:background}) and yet give
  as little leeway to a malicious node as possible. This has an unfortunate side
  effect, however. BFT can always recover from network partitions \cite[Section
  1, Introduction]{cryptoeprint:2018:1049}, but this is not true for PBFT: in a
  setting with 7 core nodes (the same setting as considered in the PBFT
  specification), a 4:3 network partition would quickly lead to \emph{both}
  partitions being unable to produce more blocks; after all, the nodes in the
  partition of 4 nodes would each sign 1/4th of the blocks, and the nodes in the
  partition of 3 nodes would each sign 1/3rd. Both partitions would therefore
  quickly stop producing blocks. Picking 0.25 for the threshold instead of 0.22
  would alleviate this problem, and would still be conform the PBFT
  specification, which says that the value must be in the closed interval
  $[\frac{1}{5}, \frac{1}{4}]$. Since PBFT is however no longer required (the
  Byron era is past and fresh deployments would not need Permissive BFT but
  could use regular BFT), it's probably not worth reconsidering this, although
  it \emph{is} relevant for the consensus tests (\cref{testing:dire}).
%
  \item[Blockchain extension] (\cref{bft:extension}).
  The leadership check implemented as part of PBFT is conform specification
  (\cref{bft:leadershipcheck}). The rest of this section matches the
  implementation, modulo some details some of which we already alluded to above:
%
  \begin{itemize}
    \item The block format is slightly different; for instance, we only have a
    single signature (\cref{footnote:singlesignature}).
    \item Blocks in Byron have a maximum size, so we cannot necessarily take
    \emph{all} valid transactions from the mempool.
    \item Block diffusion is not limited to the suffix of the chain: clients
    can request \emph{any} block that's on the chain. This is of course critical
    to allow nodes to join the network later, something which the BFT paper does
    not consider.
  \end{itemize}
%
  It should also be pointed out that we consider neither block production nor
  block diffusion to be part of the consensus protocol at all; only the
  leadership check itself is.

  \item[Ledger reporting].
  Although we do offer a way to query the state of the ledger
  (\cref{ledger:queries}), we do not offer a query to distinguish between
  finalised/pending blocks.
  \todo{TODO} TODO: It's also not clear to me why the BFT specification would
  consider a block to be finalised as soon as it's $3t + 1$ blocks deep
  (where $t$ is the maximum number of core nodes). The paper claims that BFT
  can always recover from a network partition, and the chain selection rule
  in the paper requires supporting infinite rollback.

\end{description}

\begin{figure}
\small
\hrule
\textbf{Parameters}:

\vspace{1em}

\begin{tabular}{c|l}
$n$ & total number of core nodes \\
$t$ & maximum number of core nodes \\
    & (we do not make this distinction between $n$ and $t$ in the consensus layer, effectively setting $n = t$) \\
$u$ & time to live (TTL) of a transaction \\
\end{tabular}

\vspace{1em}

\textbf{Protocol}: \\

The $i$-th server locally maintains a blockchain $B_0 B_1 \ldots B_l$, an
ordered sequence of transactions called a mempool, and carries out the following
protocol:

\begin{description}
  \item[Clock update and network delivery] With each advance of the clock to a
  slot $\mathit{sl}_j$, a collection of transactions and blockchains are pushed
  to the server by the network layer. Following this, the server proceeds as
  follows:
  %
  \begin{enumerate}
    \item \textbf{Mempool update}.\label{bft:mempool}
      \begin{enumerate}
        \item \label{bft:mempool:consistency} Whenever a transaction
        $\mathit{tx}$ is received, it is added to the mempool as long as it is
        consistent with
        \begin{enumerate}
          \item the existing transactions in the mempool and
          \item the contents of the local blockchain.
        \end{enumerate}
        \item \label{bft:mempool:ttl} The transaction is maintained in the
        mempool for $u$ rounds, where $u$ is a parameter.
        \item \label{bft:mempool:receipts} Optionally, when the transaction
        enters the mempool the server can return a signed receipt back to the
        client that is identified as the sender.
      \end{enumerate}
%
  \item \textbf{Blockchain update}.\label{bft:update} Whenever the server
  becomes aware of an alternative blockchain
  $B_0 B_1' \ldots B'_s$
  with $s > l$, it replaces its local chain with this new chain provided it is
  valid, i.e. each one of its blocks
  $(h, d, \mathit{sl}_j, \sigma_\mathit{sl}, \sigma_\mathrm{block})$
%
  \begin{enumerate}
    \item \label{bft:update:signatures} contains proper signatures
    \begin{enumerate}
      \item one for time slot $\mathit{sl}_j$ and
      \item one for the entire block
    \end{enumerate}
    by server $i$ such that $i - 1 = (j - 1) \bmod n$
    \item \label{bft:update:hash} $h$ is the hash of the previous block, and
    \item \label{bft:update:body} $d$ is a valid sequence of transactions w.r.t.
    the ledger defined by the transactions found in the previous blocks
  \end{enumerate}
%
  \item \textbf{Blockchain extension}.\label{bft:extension} Finally, the server
  checks if it is responsible to issue the next block by testing if
%
  \begin{equation}
    i - 1 = (j - 1) \bmod n
  \label{bft:leadershipcheck}
  \end{equation}
%
  In such case, this $i$-th server is the slot leader. It
%
  \begin{itemize}
    \item collects the set $d$ of all valid transactions from its mempool and
    \item appends the block $B_{l+1} = (h, d, \mathit{sl}_j, \sigma_\mathit{sl}, \sigma_\mathrm{block})$ to its blockchain, where
    \begin{equation*}
      \begin{split}
      \sigma_\mathit{sl}    & = \mathsf{Sign}_{\mathsf{sk}_i}(\mathit{sl}_j) \\
      \sigma_\mathrm{block} & = \mathsf{Sign}_{\mathsf{sk}_i}(h, d, \mathit{sl}_j, \sigma_\mathit{sl}) \\
      h                     & = H(B_l) \\
      \end{split}
    \end{equation*}
    It then diffuses $B_{l+1}$ as well as any requested blocks from the suffix of its blockchain that covers the most recent $2t + 1$ slots.
    \end{itemize}

  \end{enumerate}

  \item[Ledger Reporting] Whenever queried, the server reports as ``finalised'' the ledger of transactions contained in the blocks $B_0 \ldots B_m, m \le l$, where $B_m$ has a slot time stamp more than $3t + 1$ slots in the past. Blocks $B_{m+1} \ldots B_l$ are reported as ``pending''.
\end{description}

\hrule
\caption{\label{figure:bft}Ouroboros-BFT \cite[Figure 1]{cryptoeprint:2018:1049}}
\end{figure}

\section{Praos}
\label{praos}

TODO: Discuss $\Delta$: When relating the papers to the implementation, we
loosely think of $\Delta$ as roughly having value 5, i.e., there is a maximum
message delay of 5 slots. However, this link to the paper is tenuous at best:
the messages the paper expects the system to send, and the messages that the
system \emph{actually} sends, are not at all the same. Defining how these relate
more precisely would be critical for a more formal statement of equivalence
between the paper and the implementation, but such a study is well outside the
scope of this report.

\subsection{Active slot coefficient}
\label{praos:f}

\subsection{Implementation}

\subsection{Relation to the paper}
\label{praos-paper}

\cite{cryptoeprint:2018:378}

\section{Combinator: Override the leader schedule}
\label{consensus:override-leader-schedule}

\cleardoublepage
\section{Separation of responsibility between consensus and ledger}

\subsection{Vision}

In the vision that underlies the abstract design of the consensus layer,
the separation of responsibility between the consensus layer and the
ledger layer happens along three axes.

\begin{description}
\item{Block \emph{selection} versus block \emph{contents}}

The primary objective of the consensus layer is to ensure that \emph{consensus}
is reached: that is, everyone agrees on (a sufficiently long prefix of) the
chain. From a sufficiently high vantage point, the consensus layer could
reasonably be described as an implementation of the various Ouroboros papers
(Praos, Genesis, etc.). A critical component of this is \emph{chain selection},
choosing between competing chains. The consensus layer does not need to be aware
of what is inside the blocks that it is choosing between.

By contrast, the ledger layer is not aware of multiple chains at all, and will
never need to execute chain selection: it exclusively deals with linear
histories. \emph{Its} primary objective is to define the contents of blocks,
along with rules that interpret those contents, computing the \emph{ledger
state}.

\item{\emph{Construction} versus \emph{verification}}

The ledger layer only ever deals with fully formed blocks. Its responsibility is
to \emph{verify} those blocks and describe how they transform the ledger state.
But those blocks need to come from somewhere in the first place; block
\emph{construction} is the responsibility of the consensus layer. This dichotomy
manifests itself in two ways:

\begin{itemize}
\item When the ledger layer verifies a block, it must verify whether or not the
node that produced the block had the right to do so, that is, whether or not it
was a slot leader in the block's slot (though it may be argued that this should
be a consensus concern instead, see below). Typically, it will need only access
to the node's \emph{public} key to do so. Note that multiple nodes may have the
right to produce a block in any given slot; the ledger layer is not checking
for \emph{the} slot leader, but rather for \emph{a} slot leader.

By contrast, the consensus layer is not checking if \emph{some} node is a leader
for slot, but rather whether \emph{it} is a leader for the current slot, and if
so, produce a block for that slot (along with evidence that it had the right to
do so). Typically, it will need access to the node's \emph{private} key in order
to execute that check.

\item Blocks are only valid with respect to a particular ledger state. Since
blocks specify their predecessor (the predecessor hash), they also implicitly
specify which ledger state they should be evaluated against: the ledger state
that was the result of applying that predecessor block (or the genesis ledger
state for the very first block).

By contrast, when the consensus layer produces a block, it must construct a
block that is valid with respect to the node's \emph{current} ledger state, and
\emph{choose} the predecessor of that new block to be the tip of the node's
current chain.

\end{itemize}

\item{\emph{Stateful} versus \emph{stateless}}

The ledger layer is entirely stateless: it is a pure function that accepts a
ledger state and a block as input and produces the new ledger state (or an
error if the block was invalid). State management is the responsibility of
the consensus layer:

\begin{itemize}

\item The consensus layer must maintain the current ledger state, and pass that
to the ledger layer when validating blocks that fit neatly onto the node's
current tip. In addition, the consensus must provide efficient access to
\emph{historical} ledger states, so that it can validate (and possibly adopt)
alternative forks of the chain.

\item Although the consensus layer does not need to be aware of the exact nature
of the block contents, it \emph{does} have to collect these ``transactions'' and
consider them when producing a block (the mempool, \cref{mempool}). If it
chooses to do eager transaction validation (that is, before it actually produces
a block), it will need support from the ledger layer to do; when producing a
block, it will need assistance from the ledger layer to produce the block body.

In both cases (transaction validation and block body construction), the
consensus layer is responsible for passing an appropriate ledger state to the
ledger layer. In the case of block production, the choice of ledger state is
clear: the current ledger state. For the mempool, it is slightly less clear-cut;
the mempool is effectively constructing a ``virtual'' block with a predecessor
chosen from the node's current chain, near its tip.\footnote{We could update
this ``virtual'' block every time that the node's current chain changes, so that
the virtual block's predecessor is always the current chain's tip. This however
couples two concurrent processes more tightly than required, and is moreover
costly: re-evaluating the mempool can be expensive.}

\end{itemize}

\end{description}

Ideally, the implementation of a particular consensus protocol (say, Praos)
should be usable with any choice of ledger (cryptocurrency or otherwise), and
conversely, a particular ledger (say, Shelley) should be usable with any choice
of consensus protocol  (Praos, Genesis, or indeed a different consensus protocol
entirely). The consensus protocol \emph{does} need some limited information from
the ledger, but we can provide this separately
(\cref{ledger:api:LedgerSupportsProtocol}), and abstract over what a particular
consensus algorithm needs from the ledger layer it is used with (specifically,
the \lstinline!SelectView! and the \lstinline!LedgerView!, discussed in
\cref{consensus:class:chainsel,consensus:class:ledgerview}).

\subsection{Practice}

In practice, the separation is not quite so clean. Partly this is for
historical reasons. When the Cardano blockchain was re-implemented, the new
consensus layer and the new ledger layer were developed in tandem, and it was
not always practical to have one wait for design decisions by the other.
For example, most of Praos is currently implemented in the ledger layer,
despite the ledger layer never having to do chain selection, ever. These are
issues that we can resolve with some relatively minor refactoring.

More problematic is that the current ledgers are not designed to be parametric
in a choice of consensus algorithm. Specifically, the Shelley ledger hardcodes
Praos. At some level, that statement makes no sense: the ledger layer never
needs to execute chain selection nor decide if it's a leader for a given slot.
However, the \emph{verification} of a block by the ledger layer currently
includes verification of the cryptographic proof produced by the consensus layer
when constructing a block. This is specific to Praos; other consensus algorithms
may require entirely different fields in the block (header). So while the ledger
layer is morally independent from the choice of consensus algorithm, in practice
it includes just enough information that running it with a different consensus
algorithm is difficult to do.

In an ideal world, the Shelley ledger would not be aware of the consensus
algorithm at all. Since the implementation of the consensus protocol, and
details of the fields required in blocks to support that protocol, are the
responsibility of the consensus layer, it would make sense to move the
leader verification check from the ledger layer into the consensus header check
instead. Block assembly now becomes more of a joint effort between the
consensus layer and the ledger layer: the ledger layer produces the block body
and some fields in the block header\footnote{In an perfect world this
header/body boundary would align neatly with the consensus/ledger boundary; I
think this ought to be possible in principle, but in the current design this is
non-trivial to achieve, since the ledger layer is interpreting some fields in
the header; for example, it is executing some rules in response to epoch
transitions, which it detects based on fields in the header.}), whereas the
consensus layer produces the fields in the block header that are required by the
consensus protocol.

Unfortunately, disentangling the two isn't \emph{quite} that easy. In
particular, the Shelley ledger supports key delegation, which is affecting
the leadership check. Disentangling this would be non-trivial; it's not
clear what consensus-protocol independent delegation would even \emph{mean}
and what kind of data it should carry. Solving this will probably require
some parameterization in the \emph{other} direction, with the ledger
rules for delegation allowing for some protocol specific data to be included.
