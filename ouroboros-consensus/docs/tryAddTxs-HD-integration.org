#+TITLE: tryAddTxs integration with HD API

* When should reads be issued?

Function =tryAddTxs= gets indirectly called in:
- [[file:~/development/input-output-hk/ouroboros-network/ouroboros-consensus/src/Ouroboros/Consensus/MiniProtocol/LocalTxSubmission/Server.hs::localTxSubmissionServer tracer mempool =][localTxSubmissionServer]]
- [[file:~/development/input-output-hk/ouroboros-network/ouroboros-consensus/src/Ouroboros/Consensus/NodeKernel.hs::getMempoolWriter mempool = Inbound.TxSubmissionMempoolWriter][getMempoolWriter]]
  - [[file:~/development/input-output-hk/ouroboros-network/ouroboros-consensus/src/Ouroboros/Consensus/Network/NodeToNode.hs::, hTxSubmissionServer = \version peer ->][tTxSubmissionServer]]

So I don't think we have much leeway to issue reads earlier than at =tryAddTxs=.
Otherwise we'd have to modify the mini-protocols.

* Modifications required to have tryAddTxs use the HD backend

Assume we want to try to add a list =txs= of transactions to the mempool.

#+begin_src haskell
txs = [tx0, tx1, ..., txn]
#+end_src

*** Acquire a flush lock on the LedgerDB

We need to acquire a *flush* lock on the =LedgerDB=. This might not be
essential, however locking gives us a simple design to start with.

*** Get the keysets for =txs=

We want to read from disk the values of the keys required to validate all
transactions in =txs=, this means that we'll need a function with type:

#+begin_src haskell
getTxsKeySets :: [GenTx blk] -> TableKeySets (LedgerState blk)
#+end_src

Then we can use it as follows:
#+begin_src haskell
kss = getTxsKeySets txs :: TableKeySets (LedgerState blk)
#+end_src

Note that in =kss= we *lost the correspondence* between keysets and
transactions. This means that the intermediate ledger state will be enriched by
the values needed to process *all* the transactions in =txs=, *before* we start
validating the first transaction in said list.
*** Rewind the mempool's internal changelog

Calling =rewindTableKeySets= requires having a changelog. This changelog should
contain all the changes that resulted from applying the transactions in the
mempool. So the internal state could have a variable of the form:

#+begin_src haskell
isChangelog :: DbChangelog' LedgerState
#+end_src

This =DbChangelog'= could be a structure that supports only the rewind, forward,
and extension operations (so for instance we won't be able to do any flushing in
the mempool).

Using =isChangelog= we could obtain the rewound keysets:

#+begin_src haskell
rkss = rewindTableKeySets isChangelog kss :: RewoundTableKeySets (LedgerState blk)
#+end_src

... and readily get the unforwarded read sets.

*** Read from the database, forward, and enrich an internal state

#+begin_src haskell
urss = readDb rkss :: UnforwardedReadSets (LedgerState blk)
#+end_src

Finally, we obtain the forwarded readsets and use it to *elaborate* the
*starting state* from which we will start validating the transactions in =txs=.

#+begin_src haskell
case forwardTableReadSets isDbChangelog urss of
  Nothing -> error "This should not happen, since the mempool is holding a lock."
  Just rss ->
    -- TODO this is the intermediate state we need to pass to the transaction
    -- validation loop. We need to find how.
    { ...
      iStateForApplyTxs = withLedgerTables (changelogCurrentState isDbChangelog) rss
    }
#+end_src


*** Validate individual transactions

Unlike blocks, transactions are validated one-by-one. For each =txi= in =txs=,
we'd apply this transaction and update the intermediate state, say
=iStateForApplyTxs=.

#+begin_src haskell
{ ...
    iStateForApplyTxs =  applyTx txi $ iStateForApplyTxs
}
 #+end_src

*** Update the internal changelog after applying the valid transactions in =txs=
After the valid transactions are applied we will have a state that will contain
the result of applying the valid transactions of =txs= to the enriched ledger
state at the tip of the internal changelog.

#+begin_src haskell
{ ...
  isDbChangelog = extendDbChangelog (stateSeqNo iStateForApplyTxs)
                                    (trackingTablesToDiffs iStateForApplyTxs)
                                    isDbChangelog
  ...
}
#+end_src

*** Release the lock

After we are done adding the transactions we can release the *flush* lock on the
=LedgerDB=.

* Required changes

*** Alter the mempool's ledger interface to support LedgerDB flush lock

*** Alter the mempool's ledger interface to support querying the current changelog

*** Add a temporary intermediate changelog like structure to the internal state

We'll need this to issue forward and rewinds. This structure should not support
flushes.

* Notes

*** Why do we need to lock the changelog?
We might not need the lock, but it help us to avoid complicated cases.

Locking is needed while rewinding and reading:
- Rewinding takes place against a given disk anchor.
- If the disk anchor changes (due to flushing), then the read will be invalid,
  forcing us to re-issue the read.

It might not be a problem to retry when the changelog was flushed between a
rewind and a read. Flushes won't occur frequently.

Locking help us with the state queries, where we don't want to change the
protocol to account for failures resulting from a stale changelog. But for the
mempool we have more wiggle room. In the future, we might want to explore an alternative mempool design in which LedgerDB flush locks are not needed.
